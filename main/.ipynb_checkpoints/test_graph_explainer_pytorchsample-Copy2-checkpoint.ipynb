{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch_geometric \n",
    "from torch_geometric.datasets import GeometricShapes\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import dgl\n",
    "from dgl.data import MiniGCDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from gnnexplainer.explain import Explainer,ExplainModule\n",
    "# from torch_geometric.nn import  GNNExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# A dataset with 80 samples, each graph is\n",
    "# of size [10, 20]\n",
    "trainset = MiniGCDataset(600, 12, 20)\n",
    "testset = MiniGCDataset(60, 12, 20)\n",
    "graph, label = trainset[2]\n",
    "fig, ax = plt.subplots()\n",
    "nx.draw(graph.to_networkx(), ax=ax)\n",
    "ax.set_title('Class: {:d}'.format(label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(labels)\n",
    "\n",
    "train_data_loader = DataLoader(trainset, batch_size=1, shuffle=True,collate_fn=collate)\n",
    "\n",
    "traindata=[]\n",
    "for iter, (g,label) in enumerate(train_data_loader):\n",
    "    if(label == 5):\n",
    "        traindata.append((g,0))\n",
    "    if(label == 7):\n",
    "        traindata.append((g,1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,in_dim, hidden_dim, n_classes):\n",
    "        super(Net, self).__init__()\n",
    "#         self.lin = Sequential(Linear(10, 10))\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h1 = F.relu(self.conv1(x, edge_index))\n",
    "        h2 = F.dropout(h1, training=self.training)\n",
    "        h3 = F.relu(self.conv2(h2, edge_index))\n",
    "        y = torch.mean(h3, 0, True)\n",
    "        return self.classify(y),h1,h2,h3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "training_epoch = 300 #original = 1500 for 1 training sample 500 for 20 samples\n",
    "initial_lr = 0.001\n",
    "\n",
    "model_name = 'explaingraph_epoch30005-May-2020-13:32:24'\n",
    "\n",
    "# model_name = '4-class-model_10-samples_500-epoch_acc-99.500000_1-errs_12-Apr-2020-14:35:45'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "SAVE_PATH = './models/' + model_name\n",
    "model = Net(1, 256, 2).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr = initial_lr, momentum=0.9, weight_decay=5e-4)\n",
    "checkpoint = torch.load(SAVE_PATH)\n",
    "checkpoint = torch.load(SAVE_PATH)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "print(device)\n",
    "training=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "#model = Classifier(1, 256, trainset.num_classes)\n",
    "import time\n",
    "from datetime import datetime\n",
    "if (training=='New'):\n",
    "    model = Net(1, 256, 2).to(device)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_losses = []\n",
    "\n",
    "    #start timer:\n",
    "    t0 = time.time()\n",
    "\n",
    "    for epoch in range(training_epoch):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for iter, (g,label) in enumerate(traindata):\n",
    "            x = g.in_degrees().view(-1, 1).float().to(device)\n",
    "\n",
    "#             x = torch.ones(g.batch_num_nodes[0],1).cuda()\n",
    "            a = g.edges()[0].tolist()\n",
    "            b = g.edges()[1].tolist()\n",
    "            edges = list(zip(a,b))\n",
    "            edges = np.array(edges)\n",
    "            edges = torch.LongTensor(edges.transpose()).to(device)\n",
    "            labels = np.array([label])\n",
    "\n",
    "            prediction,h1,h2,h3 = model(x,edges)\n",
    "            loss = loss_func(prediction, torch.LongTensor(labels).cuda())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "    #         print('loss {:.4f},label:{}'.format(loss,label))\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.detach().item()\n",
    "        epoch_loss /= (iter + 1)\n",
    "        print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "    training_time = time.time() - t0\n",
    "\n",
    "    print('Finished training. Training time = {:.4f} Seconds'.format(training_time))\n",
    "\n",
    "\n",
    "    dateTimeObj = datetime.now()\n",
    "\n",
    "    timestampStr = dateTimeObj.strftime(\"%d-%b-%Y-%H:%M:%S\")\n",
    "    model_name = 'explaingraph_epoch{}'.format(training_epoch)+timestampStr\n",
    "\n",
    "    SAVE_PATH = './models/' + model_name\n",
    "    torch.save({'epoch':epoch,'model_state_dict':model.state_dict(),'optimizer_state_dict': optimizer.state_dict()}, SAVE_PATH)\n",
    "    plt.title('cross entropy averaged over minibatches')\n",
    "    plt.plot(epoch_losses)\n",
    "    plt.show()\n",
    "if(training=='continue'):\n",
    "\n",
    "    \n",
    "    for epoch in range(training_epoch):\n",
    "        epoch += start_epoch\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for iter, (g,label) in enumerate(traindata):\n",
    "            x = g.in_degrees().view(-1, 1).float().to(device)\n",
    "\n",
    "#             x = torch.ones(g.batch_num_nodes[0],1).cuda()\n",
    "            a = g.edges()[0].tolist()\n",
    "            b = g.edges()[1].tolist()\n",
    "            edges = list(zip(a,b))\n",
    "            edges = np.array(edges)\n",
    "            edges = torch.LongTensor(edges.transpose()).to(device)\n",
    "            labels = np.array([label])\n",
    "\n",
    "            prediction,h1,h2,h3 = model(x,edges)\n",
    "\n",
    "            loss = loss_func(prediction, torch.LongTensor(labels).cuda())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "    #         print('loss {:.4f},label:{}'.format(loss,label))\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.detach().item()\n",
    "        epoch_loss /= (iter + 1)\n",
    "        print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    torch.save({'epoch':epoch,'model_state_dict':model.state_dict(),'optimizer_state_dict': optimizer.state_dict()}, SAVE_PATH)\n",
    "    plt.title('cross entropy averaged over minibatches')\n",
    "    plt.plot(epoch_losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(DGLGraph(num_nodes=12, num_edges=44,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 0, 35), (DGLGraph(num_nodes=15, num_edges=59,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 0, 36), (DGLGraph(num_nodes=15, num_edges=59,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 0, 37), (DGLGraph(num_nodes=12, num_edges=44,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 0, 38), (DGLGraph(num_nodes=16, num_edges=64,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 0, 39), (DGLGraph(num_nodes=10, num_edges=36,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 0, 40), (DGLGraph(num_nodes=15, num_edges=59,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 0, 41), (DGLGraph(num_nodes=16, num_edges=64,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 49), (DGLGraph(num_nodes=14, num_edges=56,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 50), (DGLGraph(num_nodes=14, num_edges=56,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 51), (DGLGraph(num_nodes=18, num_edges=72,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 52), (DGLGraph(num_nodes=18, num_edges=72,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 53), (DGLGraph(num_nodes=12, num_edges=48,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 54), (DGLGraph(num_nodes=18, num_edges=72,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 55), (DGLGraph(num_nodes=14, num_edges=56,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 56), (DGLGraph(num_nodes=18, num_edges=72,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 57), (DGLGraph(num_nodes=16, num_edges=64,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 58), (DGLGraph(num_nodes=16, num_edges=64,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}), 1, 59)]\n"
     ]
    }
   ],
   "source": [
    "test_data_loader=DataLoader(testset, batch_size=1, shuffle=False,collate_fn=collate)\n",
    "\n",
    "test_data = []\n",
    "for iter, (g,label) in enumerate(test_data_loader):\n",
    "    if(label==5):\n",
    "        test_data.append((g,0,iter))\n",
    "    if(label==7):\n",
    "        test_data.append((g,1,iter))\n",
    "        \n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 7.4230e-07]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[0]], device='cuda:0') 0\n",
      "tensor([[0.9753, 0.0247]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[0]], device='cuda:0') 0\n",
      "tensor([[0.9777, 0.0223]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[0]], device='cuda:0') 0\n",
      "tensor([[1.0000e+00, 1.1015e-07]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[0]], device='cuda:0') 0\n",
      "tensor([[0.7347, 0.2653]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[0]], device='cuda:0') 0\n",
      "tensor([[1.0000e+00, 2.6078e-10]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[0]], device='cuda:0') 0\n",
      "tensor([[0.9926, 0.0074]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[0]], device='cuda:0') 0\n",
      "tensor([[0.0731, 0.9269]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.0725, 0.9275]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.1278, 0.8722]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.0724, 0.9276]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.3289, 0.6711]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.0718, 0.9282]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.0762, 0.9238]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.1265, 0.8735]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.0961, 0.9039]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.0710, 0.9290]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n",
      "tensor([[0.0803, 0.9197]], device='cuda:0', grad_fn=<SoftmaxBackward>) tensor([[1]], device='cuda:0') 1\n"
     ]
    }
   ],
   "source": [
    "model.eval\n",
    "\n",
    "prediction=torch.zeros(len(test_data),1,dtype=torch.float64)\n",
    "for iter, (g,label,_) in enumerate(test_data):\n",
    "        x = g.in_degrees().view(-1, 1).float().cuda()\n",
    "        a = g.edges()[0].tolist()\n",
    "        b = g.edges()[1].tolist()\n",
    "        edges = list(zip(a,b))\n",
    "        edges = np.array(edges)\n",
    "        edges = torch.LongTensor(edges.transpose()).cuda()\n",
    "        labels = np.array([label])\n",
    "\n",
    "        pred,h1,h2,h3 = model(x,edges)\n",
    "        probs_Y = torch.softmax(pred, 1)\n",
    "        argmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n",
    "#         prediction[iter] = (argmax_Y.cuda()==label.cuda())\n",
    "        prediction[iter] = (argmax_Y==label)\n",
    "        print(probs_Y,argmax_Y,label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of argmax predictions on the test set: 100.0000%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of argmax predictions on the test set: {:.4f}%'.format(\n",
    "    (prediction.cuda().sum().item() / len(test_data)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## model.eval()\n",
    "# for iter, (g,label,index) in enumerate(test_data):\n",
    "#     test_g = g\n",
    "#     label_tensor =label\n",
    "\n",
    "\n",
    "#     # test_g, label = trainset[2]\n",
    "#     fig, ax = plt.subplots()\n",
    "#     nx.draw(test_g.to_networkx(), ax=ax)\n",
    "#     x = test_g.in_degrees().view(-1, 1).float()\n",
    "#     mean_degree = torch.mean(x)\n",
    "#     ax.set_title('Class: {}, Mean Degree:{},iter:{}'.format(label,mean_degree,index))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 256) (16, 256) (16, 256)\n",
      "<bound method Module.parameters of Net(\n",
      "  (conv1): GCNConv(1, 256)\n",
      "  (conv2): GCNConv(256, 256)\n",
      "  (classify): Linear(in_features=256, out_features=2, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "# torch.save(h1.data, 'file.pt')\n",
    "\n",
    "pred,h1,h2,h3 = model(x.cuda(),edges.cuda())\n",
    "h1 = h1.cpu().detach().numpy()\n",
    "h2 = h2.cpu().detach().numpy()\n",
    "h3 = h3.cpu().detach().numpy()\n",
    "print(h1.shape,h2.shape,h3.shape)\n",
    "print(model.parameters)\n",
    "np.savetxt(\"h1.csv\", h1, delimiter=\",\", fmt='%f',header='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGLGraph(num_nodes=18, num_edges=72,\n",
      "         ndata_schemes={}\n",
      "         edata_schemes={}) 7\n",
      "[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14, 15, 15, 15, 16, 16, 16, 17, 17, 17, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[1, 9, 8, 0, 2, 10, 1, 3, 11, 2, 4, 12, 3, 5, 13, 4, 6, 14, 5, 7, 15, 6, 8, 16, 7, 17, 0, 10, 0, 17, 9, 11, 1, 10, 12, 2, 11, 13, 3, 12, 14, 4, 13, 15, 5, 14, 16, 6, 15, 17, 7, 16, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "tensor([[-1.1905,  1.1633]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3105ca781dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m explainer = Explainer(\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0madj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'x'"
     ]
    }
   ],
   "source": [
    "\n",
    "test_g,label = testset[55]\n",
    "print(test_g,label)\n",
    "label = 0\n",
    "x = test_g.in_degrees().view(-1, 1).float().cuda()\n",
    "# x = feature\n",
    "a = test_g.edges()[0].tolist()\n",
    "print(a)\n",
    "\n",
    "b = test_g.edges()[1].tolist()\n",
    "print(b)\n",
    "edges= list(zip(a,b))\n",
    "edges=np.array(edges)\n",
    "edges=torch.LongTensor(edges.transpose()).cuda()\n",
    "probs_Y,h1,h2,h3 = model(x, edges)\n",
    "print(probs_Y)\n",
    "\n",
    "explainer = Explainer(\n",
    "            model=model,\n",
    "            adj=edges,\n",
    "            feat=x,\n",
    "            label=label,\n",
    "            pred = probs_Y\n",
    "            train_idx=None,\n",
    "            graph_mode=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ExplainModule' object has no attribute 'explain_graphs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e7d0b65b6f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_subgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    594\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ExplainModule' object has no attribute 'explain_graphs'"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import k_hop_subgraph, to_networkx\n",
    "import numpy as np\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "edge_mask,epoch_losses = explainer.explain_graphs(0)\n",
    "\n",
    "plt = explainer.visualize_subgraph(None,edge_index=edges, edge_mask=edge_mask,threshold=0.1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('cross entropy averaged over minibatches')\n",
    "plt.plot(epoch_losses)\n",
    "plt.show()\n",
    "# print(node_feat_mask)\n",
    "print(edge_mask)\n",
    "print(edges[0,edge_mask>0.2])\n",
    "print(edges[1,edge_mask>0.2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop all test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from torch.utils.tensorboard import SummaryWriter\n",
    "# # writer = SummaryWriter()\n",
    "# for iter, (g,label) in enumerate(test_data):\n",
    "#         plt.clf()\n",
    "#         fig, ax = plt.subplots(1,2,figsize=(12,6))\n",
    "#         nx.draw(g.to_networkx(), ax=ax[0])\n",
    "        \n",
    "#         image_name = 'graph_{}'.format(iter)\n",
    "#         plt.savefig(\"./images/original/\"+image_name+ \".png\")\n",
    "#         x = g.in_degrees().view(-1, 1).float().cuda()\n",
    "#         a = g.edges()[0].tolist()\n",
    "#         b = g.edges()[1].tolist()\n",
    "#         edges = list(zip(a,b))\n",
    "#         edges = np.array(edges)\n",
    "#         edges = torch.LongTensor(edges.transpose()).cuda()\n",
    "#         labels = np.array([label])\n",
    "#         node_feat_mask, edge_mask,epoch_losses = explainer.explain_graph(x=x, edge_index=edges)\n",
    "\n",
    "#         plt1 = explainer.visualize_subgraph(None, edge_index=edges.cpu(), edge_mask=edge_mask,threshold=None)\n",
    "\n",
    "#         plt.savefig(\"./images/\"+image_name+ \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import k_hop_subgraph, to_networkx\n",
    "def visualize(node_idx, edge_index, edge_mask, y=None,\n",
    "                           threshold=None,**kwargs):\n",
    "        assert edge_mask.size(0) == edge_index.size(1)\n",
    "        \n",
    "        if threshold is not None:\n",
    "            print('Edge Threshold:',threshold)\n",
    "            edge_mask = (edge_mask >= threshold).to(torch.float)\n",
    "          \n",
    "        if node_idx is not None:\n",
    "            # Only operate on a k-hop subgraph around `node_idx`.\n",
    "            subset, edge_index, hard_edge_mask = k_hop_subgraph(\n",
    "                node_idx, self.__num_hops__(), edge_index, relabel_nodes=True,\n",
    "                num_nodes=None, flow=self.__flow__())\n",
    "\n",
    "            edge_mask = edge_mask[hard_edge_mask]\n",
    "        else:\n",
    "            subset=[]\n",
    "            for index,mask in enumerate(edge_mask):\n",
    "                node_a = edge_index[0,index]\n",
    "                node_b = edge_index[1,index]\n",
    "                if node_a not in subset:\n",
    "                    subset.append(node_a.cpu().item())\n",
    "#                     print(\"add: \"+node_a)\n",
    "                if node_b not in subset:\n",
    "                    subset.append(node_b.cpu().item())\n",
    "#                     print(\"add: \"+node_b)\n",
    "#             subset = torch.cat(subset).unique()\n",
    "        edge_list=[]\n",
    "        for index, edge in enumerate(edge_mask):\n",
    "            if edge:\n",
    "                edge_list.append((edge_index[0,index].cpu(),edge_index[1,index].cpu()))\n",
    "        \n",
    "        if y is None:\n",
    "            y = torch.zeros(edge_index.max().item() + 1,\n",
    "                            device=edge_index.device)\n",
    "        else:\n",
    "            y = y[subset].to(torch.float) / y.max().item()\n",
    "\n",
    "        data = Data(edge_index=edge_index.cpu(), att=edge_mask, y=y,\n",
    "                    num_nodes=y.size(0)).to('cpu')\n",
    "\n",
    "        G = to_networkx(data, node_attrs=['y'], edge_attrs=['att'])\n",
    "#         mapping = {k: i for k, i in enumerate(subset.tolist())}\n",
    "        mapping = {k: i for k, i in enumerate(subset)}\n",
    "#         print(mapping)\n",
    "#         G = nx.relabel_nodes(G, mapping)\n",
    "\n",
    "        kwargs['with_labels'] = kwargs.get('with_labels') or True\n",
    "        kwargs['font_size'] = kwargs.get('font_size') or 10\n",
    "        kwargs['node_size'] = kwargs.get('node_size') or 200\n",
    "        kwargs['cmap'] = kwargs.get('cmap') or 'cool'\n",
    "\n",
    "        pos = nx.spring_layout(G)\n",
    "        ax = plt.gca()\n",
    "        for source, target, data in G.edges(data=True):\n",
    "            ax.annotate(\n",
    "                '', xy=pos[target], xycoords='data', xytext=pos[source],\n",
    "                textcoords='data', arrowprops=dict(\n",
    "                    arrowstyle=\"-\",\n",
    "                    alpha=max(data['att'], 0.1),\n",
    "                    shrinkA=sqrt(kwargs['node_size']) / 2.0,\n",
    "                    shrinkB=sqrt(kwargs['node_size']) / 2.0,\n",
    "#                     connectionstyle=\"arc3,rad=0.1\",\n",
    "                ))\n",
    "# #         if node_feature_mask is not None:\n",
    "        nx.draw_networkx_nodes(G, pos, **kwargs)\n",
    "\n",
    "        color = np.array(edge_mask.cpu())\n",
    "\n",
    "        nx.draw_networkx_edges(G, pos,\n",
    "                       width=3, alpha=0.5, edge_color=color,edge_cmap=plt.cm.Reds)\n",
    "        nx.draw_networkx_labels(G, pos, **kwargs)\n",
    "        plt.axis('off')\n",
    "        return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = visualize(None,edge_index=edges, edge_mask=edge_mask,threshold=0.1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "G=test_g.to_networkx()\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G,pos,ax=ax)\n",
    "# nx.draw_networkx_nodes(G, pos,ax=ax)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "print(edges)\n",
    "print(edge_mask>0.1)\n",
    "print(edges[0,edge_mask>0.1])\n",
    "print(edges[1,edge_mask>0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_new = MiniGCDataset(10, 6, 10)\n",
    "for iter, (g,label) in enumerate(testset_new):\n",
    "    test_g = g\n",
    "    label_tensor =label\n",
    "    # test_g, label = trainset[2]\n",
    "    fig, ax = plt.subplots()\n",
    "    nx.draw(test_g.to_networkx(), ax=ax)\n",
    "    x = test_g.in_degrees().view(-1, 1).float()\n",
    "    mean_degree = torch.mean(x)\n",
    "    ax.set_title('Class: {}, Mean Degree:{},iter:{}'.format(label,mean_degree,iter))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_graph,test_label = testset_new[7]\n",
    "print(test_graph)\n",
    "fig, ax = plt.subplots()\n",
    "nx.draw(test_graph.to_networkx(), ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_graph.in_degrees().view(-1, 1).float().cuda()\n",
    "\n",
    "a = test_graph.edges()[0].tolist()\n",
    "b = test_graph.edges()[1].tolist()\n",
    "edges = list(zip(a,b))\n",
    "edges = np.array(edges)\n",
    "edges = torch.LongTensor(edges.transpose()).cuda()\n",
    "test_label = np.array([test_label])\n",
    "\n",
    "pred,h1,h2,h3 = model(x,edges)\n",
    "probs_Y = torch.softmax(pred, 1)\n",
    "argmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n",
    "prediction = (argmax_Y==label)\n",
    "prediction = (argmax_Y==label)\n",
    "print(probs_Y,argmax_Y,test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
