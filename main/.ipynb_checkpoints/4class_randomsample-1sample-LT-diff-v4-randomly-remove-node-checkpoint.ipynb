{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup GPU Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Set GPU IDs for training:\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "def build_circuit_graph_undirected(node_list,edge_list):\n",
    "    g = dgl.DGLGraph()\n",
    "    g.add_nodes(len(node_list))\n",
    "    src, dst = tuple(zip(*edge_list))\n",
    "    g.add_edges(src, dst)\n",
    "    g.add_edges(dst, src)\n",
    "    return g\n",
    "\n",
    "def build_circuit_graph_directed_sd(node_list,edge_list):\n",
    "    g = dgl.DGLGraph()\n",
    "    g.add_nodes(len(node_list))\n",
    "    src, dst = tuple(zip(*edge_list))\n",
    "    g.add_edges(src, dst)\n",
    "    return g\n",
    "\n",
    "def build_circuit_graph_directed_ds(node_list,edge_list):\n",
    "    g = dgl.DGLGraph()\n",
    "    g.add_nodes(len(node_list))\n",
    "    src, dst = tuple(zip(*edge_list))\n",
    "    g.add_edges(dst, src)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Number of Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43 45  6 52 54 48 37 39 44 31 28 57 50  7 30 40 25 14 56 23] [43 45  6 52 54 48 37 39 44 31 28 57 50  7 30 40 25 14 56 23] [43 45  6 52 54 48 37 39 44 31 28 57 50  7 30 40 25 14 56 23] [43 45  6 52 54 48 37 39 44 31 28 57 50  7 30 40 25 14 56 23]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import csv\n",
    "import numpy as np\n",
    "dir = 'training_data'\n",
    "\n",
    "trainset=[]\n",
    "labels=[]\n",
    "#for filename in os.listdir(dir):\n",
    "np.random.seed(1)\n",
    "sample_size = 20\n",
    "# training_idx = np.random.randint(4,64,10)\n",
    "training_idx_1 = np.random.choice(np.arange(4,64), size=sample_size, replace=False)\n",
    "# training_idx_2 = np.random.choice(np.arange(4,64), size=sample_size, replace=False)\n",
    "# training_idx_3 = np.random.choice(np.arange(4,64), size=sample_size, replace=False)\n",
    "# training_idx_4 = np.random.choice(np.arange(4,64), size=sample_size, replace=False)\n",
    "training_idx_2 = training_idx_1\n",
    "training_idx_3 = training_idx_1\n",
    "training_idx_4 = training_idx_1\n",
    "# training_idx_1 = [6]\n",
    "# training_idx_2 = [6]\n",
    "# training_idx_3 = [6]\n",
    "# training_idx_4 = [6]\n",
    "print(training_idx_1,training_idx_2,training_idx_3,training_idx_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3], [1], [0], [2], [3]]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(training_idx_1)):\n",
    "    node_list=[]\n",
    "    edge_list=[]\n",
    "    label_list=[]\n",
    "    node_list2=[]\n",
    "    edge_list2=[]\n",
    "    label_list2=[]\n",
    "    node_list3=[]\n",
    "    edge_list3=[]\n",
    "    label_list3=[]\n",
    "    node_list4=[]\n",
    "    edge_list4=[]\n",
    "    label_list4=[]\n",
    "    for j in [\"node_list\",\"edge_list\",\"graph_label\"]:\n",
    "        filename = \"rca_\"+str(training_idx_1[idx])+\"bit\"+j+'.csv'\n",
    "        filename2 = \"cla_\"+str(training_idx_2[idx])+\"bit\"+j+'.csv'\n",
    "        filename3 = \"csa_\"+str(training_idx_3[idx])+\"bit\"+j+'.csv'\n",
    "        filename4 = \"CSkipA_\"+str(training_idx_4[idx])+\"bit\"+j+'.csv'\n",
    "        if(filename.find(\"node_list\")>=0):\n",
    "            with open(dir+'/'+filename, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                node_list = list(reader)\n",
    "                \n",
    "        if(filename.find(\"edge_list\")>=0):\n",
    "            with open(dir+'/'+filename, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                edge_list = list(reader)\n",
    "        if(filename.find(\"graph_label\")>=0):\n",
    "            with open(dir+'/'+filename, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                label_list = list(reader)\n",
    "        if(filename.find(\"gate_type\")>=0):\n",
    "            with open(dir+'/'+filename, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                gate_type = list(reader)\n",
    "        \n",
    "        if(filename2.find(\"node_list\")>=0):\n",
    "            with open(dir+'/'+filename2, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                node_list2 = list(reader)\n",
    "                \n",
    "        if(filename2.find(\"edge_list\")>=0):\n",
    "            with open(dir+'/'+filename2, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                edge_list2 = list(reader)\n",
    "        if(filename2.find(\"graph_label\")>=0):\n",
    "            with open(dir+'/'+filename2, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                label_list2 = list(reader)\n",
    "        if(filename2.find(\"gate_type\")>=0):\n",
    "            with open(dir+'/'+filename2, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                gate_type2 = list(reader)\n",
    "        \n",
    "        if(filename3.find(\"node_list\")>=0):\n",
    "            with open(dir+'/'+filename3, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                node_list3 = list(reader)\n",
    "                \n",
    "        if(filename3.find(\"edge_list\")>=0):\n",
    "            with open(dir+'/'+filename3, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                edge_list3 = list(reader)\n",
    "        if(filename3.find(\"graph_label\")>=0):\n",
    "            with open(dir+'/'+filename3, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                label_list3 = list(reader)\n",
    "        if(filename3.find(\"gate_type\")>=0):\n",
    "            with open(dir+'/'+filename3, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                gate_type3 = list(reader)\n",
    "        if(filename4.find(\"node_list\")>=0):\n",
    "            with open(dir+'/'+filename4, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                node_list4 = list(reader)\n",
    "                \n",
    "        if(filename4.find(\"edge_list\")>=0):\n",
    "            with open(dir+'/'+filename4, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                edge_list4 = list(reader)\n",
    "        if(filename4.find(\"graph_label\")>=0):\n",
    "            with open(dir+'/'+filename4, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                label_list4 = list(reader)\n",
    "        if(filename4.find(\"gate_type\")>=0):\n",
    "            with open(dir+'/'+filename4, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                gate_type4 = list(reader)\n",
    "    #create dgl graph\n",
    "    g=build_circuit_graph_undirected(node_list,edge_list)\n",
    "    trainset.append(g)\n",
    "    labels.append(label_list[0])\n",
    "    g2=build_circuit_graph_undirected(node_list2,edge_list2)\n",
    "    trainset.append(g2)\n",
    "    labels.append(label_list2[0])\n",
    "    g3=build_circuit_graph_undirected(node_list3,edge_list3)\n",
    "    trainset.append(g3)\n",
    "    labels.append(label_list3[0])\n",
    "    g4=build_circuit_graph_undirected(node_list4,edge_list4)\n",
    "    trainset.append(g4)\n",
    "    labels.append(label_list4[0])\n",
    "\n",
    "for i in labels:\n",
    "    i[0] = int(i[0])\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph = trainset[14]\n",
    "# label=labels[14][0]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# G=graph.to_networkx()\n",
    "# pos=nx.spring_layout(G)\n",
    "# nx.draw(G,pos)\n",
    "# nx.draw_networkx_labels(G,pos, ax=ax)\n",
    "# ax.set_title('Class: {:f}'.format(label))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply random shuffle to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##apply random shuffle on the trainset\n",
    "np.random.seed(0)\n",
    "randomize = np.arange(len(trainset))\n",
    "np.random.shuffle(randomize)\n",
    "labels_shuffled=[]\n",
    "trainset_shuffled=[]\n",
    "for i in range (len(randomize)):\n",
    "    labels_shuffled.append(labels[randomize[i]])\n",
    "    trainset_shuffled.append(trainset[randomize[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "\n",
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    return batched_graph, torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Sends a message of node feature h.\n",
    "msg = fn.copy_src(src='h', out='m')\n",
    "\n",
    "def reduce(nodes):\n",
    "    \"\"\"Take an average over all neighbor node features hu and use it to\n",
    "    overwrite the original node feature.\"\"\"\n",
    "    accum = torch.mean(nodes.mailbox['m'], 1)\n",
    "    return {'h': accum}\n",
    "\n",
    "class NodeApplyModule(nn.Module):\n",
    "    \"\"\"Update the node feature hv with ReLU(Whv+b).\"\"\"\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        h = self.activation(h)\n",
    "        return {'h' : h}\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        # Initialize the node features with h.\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(msg, reduce)\n",
    "        g.apply_nodes(func=self.apply_mod)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readout and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, n_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GCN(in_dim, hidden_dim, F.relu),\n",
    "            GCN(hidden_dim, hidden_dim, F.relu)])\n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, g):\n",
    "        # For undirected graphs, in_degree is the same as\n",
    "        # out_degree.\n",
    "        h = g.in_degrees().view(-1, 1).float().cuda()\n",
    "        for conv in self.layers:\n",
    "            h = conv(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        hg = dgl.mean_nodes(g, 'h')\n",
    "        return self.classify(hg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Training Results Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.manual_seed(0)\n",
    "# #CuDNN:\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epoch = 500 #original = 1500 for 1 training sample\n",
    "initial_lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 1.6066\n",
      "Epoch 1, loss 1.4274\n",
      "Epoch 2, loss 1.3813\n",
      "Epoch 3, loss 1.3419\n",
      "Epoch 4, loss 1.2915\n",
      "Epoch 5, loss 1.2239\n",
      "Epoch 6, loss 1.1341\n",
      "Epoch 7, loss 1.0433\n",
      "Epoch 8, loss 0.9582\n",
      "Epoch 9, loss 0.8914\n",
      "Epoch 10, loss 0.8350\n",
      "Epoch 11, loss 0.7853\n",
      "Epoch 12, loss 0.7393\n",
      "Epoch 13, loss 0.6972\n",
      "Epoch 14, loss 0.6569\n",
      "Epoch 15, loss 0.6197\n",
      "Epoch 16, loss 0.5849\n",
      "Epoch 17, loss 0.5531\n",
      "Epoch 18, loss 0.5244\n",
      "Epoch 19, loss 0.4990\n",
      "Epoch 20, loss 0.4771\n",
      "Epoch 21, loss 0.4582\n",
      "Epoch 22, loss 0.4421\n",
      "Epoch 23, loss 0.4288\n",
      "Epoch 24, loss 0.4173\n",
      "Epoch 25, loss 0.4079\n",
      "Epoch 26, loss 0.3994\n",
      "Epoch 27, loss 0.3922\n",
      "Epoch 28, loss 0.3861\n",
      "Epoch 29, loss 0.3803\n",
      "Epoch 30, loss 0.3757\n",
      "Epoch 31, loss 0.3702\n",
      "Epoch 32, loss 0.3653\n",
      "Epoch 33, loss 0.3608\n",
      "Epoch 34, loss 0.3567\n",
      "Epoch 35, loss 0.3521\n",
      "Epoch 36, loss 0.3480\n",
      "Epoch 37, loss 0.3433\n",
      "Epoch 38, loss 0.3391\n",
      "Epoch 39, loss 0.3344\n",
      "Epoch 40, loss 0.3291\n",
      "Epoch 41, loss 0.3244\n",
      "Epoch 42, loss 0.3193\n",
      "Epoch 43, loss 0.3144\n",
      "Epoch 44, loss 0.3085\n",
      "Epoch 45, loss 0.3036\n",
      "Epoch 46, loss 0.2988\n",
      "Epoch 47, loss 0.2936\n",
      "Epoch 48, loss 0.2887\n",
      "Epoch 49, loss 0.2925\n",
      "Epoch 50, loss 0.2797\n",
      "Epoch 51, loss 0.2741\n",
      "Epoch 52, loss 0.2682\n",
      "Epoch 53, loss 0.2626\n",
      "Epoch 54, loss 0.2568\n",
      "Epoch 55, loss 0.2632\n",
      "Epoch 56, loss 0.2519\n",
      "Epoch 57, loss 0.2395\n",
      "Epoch 58, loss 0.2327\n",
      "Epoch 59, loss 0.2643\n",
      "Epoch 60, loss 0.2273\n",
      "Epoch 61, loss 0.2152\n",
      "Epoch 62, loss 0.2125\n",
      "Epoch 63, loss 0.1989\n",
      "Epoch 64, loss 0.1920\n",
      "Epoch 65, loss 0.1863\n",
      "Epoch 66, loss 0.1794\n",
      "Epoch 67, loss 0.1735\n",
      "Epoch 68, loss 0.1677\n",
      "Epoch 69, loss 0.1613\n",
      "Epoch 70, loss 0.1547\n",
      "Epoch 71, loss 0.1586\n",
      "Epoch 72, loss 0.1452\n",
      "Epoch 73, loss 0.1373\n",
      "Epoch 74, loss 0.1314\n",
      "Epoch 75, loss 0.1266\n",
      "Epoch 76, loss 0.1212\n",
      "Epoch 77, loss 0.1167\n",
      "Epoch 78, loss 0.1118\n",
      "Epoch 79, loss 0.1075\n",
      "Epoch 80, loss 0.1025\n",
      "Epoch 81, loss 0.0982\n",
      "Epoch 82, loss 0.0944\n",
      "Epoch 83, loss 0.0906\n",
      "Epoch 84, loss 0.0866\n",
      "Epoch 85, loss 0.0832\n",
      "Epoch 86, loss 0.0812\n",
      "Epoch 87, loss 0.0779\n",
      "Epoch 88, loss 0.0762\n",
      "Epoch 89, loss 0.0728\n",
      "Epoch 90, loss 0.0710\n",
      "Epoch 91, loss 0.0679\n",
      "Epoch 92, loss 0.0675\n",
      "Epoch 93, loss 0.0645\n",
      "Epoch 94, loss 0.0641\n",
      "Epoch 95, loss 0.0621\n",
      "Epoch 96, loss 0.0622\n",
      "Epoch 97, loss 0.0592\n",
      "Epoch 98, loss 0.0592\n",
      "Epoch 99, loss 0.0573\n",
      "Epoch 100, loss 0.0548\n",
      "Epoch 101, loss 0.0547\n",
      "Epoch 102, loss 0.0521\n",
      "Epoch 103, loss 0.0485\n",
      "Epoch 104, loss 0.0469\n",
      "Epoch 105, loss 0.0451\n",
      "Epoch 106, loss 0.0428\n",
      "Epoch 107, loss 0.0401\n",
      "Epoch 108, loss 0.0378\n",
      "Epoch 109, loss 0.0356\n",
      "Epoch 110, loss 0.0337\n",
      "Epoch 111, loss 0.0322\n",
      "Epoch 112, loss 0.0309\n",
      "Epoch 113, loss 0.0298\n",
      "Epoch 114, loss 0.0274\n",
      "Epoch 115, loss 0.0286\n",
      "Epoch 116, loss 0.0506\n",
      "Epoch 117, loss 0.0259\n",
      "Epoch 118, loss 0.0233\n",
      "Epoch 119, loss 0.0241\n",
      "Epoch 120, loss 0.0280\n",
      "Epoch 121, loss 0.0243\n",
      "Epoch 122, loss 0.0206\n",
      "Epoch 123, loss 0.0194\n",
      "Epoch 124, loss 0.0193\n",
      "Epoch 125, loss 0.0189\n",
      "Epoch 126, loss 0.0185\n",
      "Epoch 127, loss 0.0184\n",
      "Epoch 128, loss 0.0186\n",
      "Epoch 129, loss 0.0180\n",
      "Epoch 130, loss 0.0174\n",
      "Epoch 131, loss 0.0172\n",
      "Epoch 132, loss 0.0166\n",
      "Epoch 133, loss 0.0171\n",
      "Epoch 134, loss 0.0168\n",
      "Epoch 135, loss 0.0166\n",
      "Epoch 136, loss 0.0155\n",
      "Epoch 137, loss 0.0159\n",
      "Epoch 138, loss 0.0147\n",
      "Epoch 139, loss 0.0143\n",
      "Epoch 140, loss 0.0135\n",
      "Epoch 141, loss 0.0127\n",
      "Epoch 142, loss 0.0138\n",
      "Epoch 143, loss 0.0118\n",
      "Epoch 144, loss 0.0159\n",
      "Epoch 145, loss 0.0130\n",
      "Epoch 146, loss 0.0134\n",
      "Epoch 147, loss 0.0108\n",
      "Epoch 148, loss 0.0117\n",
      "Epoch 149, loss 0.0113\n",
      "Epoch 150, loss 0.0110\n",
      "Epoch 151, loss 0.0105\n",
      "Epoch 152, loss 0.0110\n",
      "Epoch 153, loss 0.0106\n",
      "Epoch 154, loss 0.0099\n",
      "Epoch 155, loss 0.0107\n",
      "Epoch 156, loss 0.0093\n",
      "Epoch 157, loss 0.0096\n",
      "Epoch 158, loss 0.0102\n",
      "Epoch 159, loss 0.0092\n",
      "Epoch 160, loss 0.0089\n",
      "Epoch 161, loss 0.0093\n",
      "Epoch 162, loss 0.0096\n",
      "Epoch 163, loss 0.0087\n",
      "Epoch 164, loss 0.0083\n",
      "Epoch 165, loss 0.0087\n",
      "Epoch 166, loss 0.0080\n",
      "Epoch 167, loss 0.0076\n",
      "Epoch 168, loss 0.0077\n",
      "Epoch 169, loss 0.0073\n",
      "Epoch 170, loss 0.0069\n",
      "Epoch 171, loss 0.0075\n",
      "Epoch 172, loss 0.0070\n",
      "Epoch 173, loss 0.0067\n",
      "Epoch 174, loss 0.0067\n",
      "Epoch 175, loss 0.0069\n",
      "Epoch 176, loss 0.0055\n",
      "Epoch 177, loss 0.0056\n",
      "Epoch 178, loss 0.0061\n",
      "Epoch 179, loss 0.0063\n",
      "Epoch 180, loss 0.0054\n",
      "Epoch 181, loss 0.0058\n",
      "Epoch 182, loss 0.0059\n",
      "Epoch 183, loss 0.0052\n",
      "Epoch 184, loss 0.0056\n",
      "Epoch 185, loss 0.0053\n",
      "Epoch 186, loss 0.0043\n",
      "Epoch 187, loss 0.0038\n",
      "Epoch 188, loss 0.0022\n",
      "Epoch 189, loss 0.0026\n",
      "Epoch 190, loss 0.0026\n",
      "Epoch 191, loss 0.0023\n",
      "Epoch 192, loss 0.0026\n",
      "Epoch 193, loss 0.0028\n",
      "Epoch 194, loss 0.0039\n",
      "Epoch 195, loss 0.2225\n",
      "Epoch 196, loss 0.0836\n",
      "Epoch 197, loss 0.0042\n",
      "Epoch 198, loss 0.0029\n",
      "Epoch 199, loss 0.0019\n",
      "Epoch 200, loss 0.0015\n",
      "Epoch 201, loss 0.0015\n",
      "Epoch 202, loss 0.0015\n",
      "Epoch 203, loss 0.0016\n",
      "Epoch 204, loss 0.0016\n",
      "Epoch 205, loss 0.0016\n",
      "Epoch 206, loss 0.0017\n",
      "Epoch 207, loss 0.0017\n",
      "Epoch 208, loss 0.0018\n",
      "Epoch 209, loss 0.0019\n",
      "Epoch 210, loss 0.0021\n",
      "Epoch 211, loss 0.0023\n",
      "Epoch 212, loss 0.0024\n",
      "Epoch 213, loss 0.0025\n",
      "Epoch 214, loss 0.0026\n",
      "Epoch 215, loss 0.0028\n",
      "Epoch 216, loss 0.0029\n",
      "Epoch 217, loss 0.0028\n",
      "Epoch 218, loss 0.0028\n",
      "Epoch 219, loss 0.0027\n",
      "Epoch 220, loss 0.0026\n",
      "Epoch 221, loss 0.0025\n",
      "Epoch 222, loss 0.0025\n",
      "Epoch 223, loss 0.0024\n",
      "Epoch 224, loss 0.0023\n",
      "Epoch 225, loss 0.0023\n",
      "Epoch 226, loss 0.0021\n",
      "Epoch 227, loss 0.0021\n",
      "Epoch 228, loss 0.0021\n",
      "Epoch 229, loss 0.0020\n",
      "Epoch 230, loss 0.0018\n",
      "Epoch 231, loss 0.0019\n",
      "Epoch 232, loss 0.0018\n",
      "Epoch 233, loss 0.0017\n",
      "Epoch 234, loss 0.0016\n",
      "Epoch 235, loss 0.0016\n",
      "Epoch 236, loss 0.0016\n",
      "Epoch 237, loss 0.0015\n",
      "Epoch 238, loss 0.0015\n",
      "Epoch 239, loss 0.0014\n",
      "Epoch 240, loss 0.0014\n",
      "Epoch 241, loss 0.0013\n",
      "Epoch 242, loss 0.0014\n",
      "Epoch 243, loss 0.0011\n",
      "Epoch 244, loss 0.0019\n",
      "Epoch 245, loss 0.0012\n",
      "Epoch 246, loss 0.0012\n",
      "Epoch 247, loss 0.0013\n",
      "Epoch 248, loss 0.0012\n",
      "Epoch 249, loss 0.0013\n",
      "Epoch 250, loss 0.0014\n",
      "Epoch 251, loss 0.0019\n",
      "Epoch 252, loss 0.5564\n",
      "Epoch 253, loss 0.2662\n",
      "Epoch 254, loss 0.0300\n",
      "Epoch 255, loss 0.0155\n",
      "Epoch 256, loss 0.0068\n",
      "Epoch 257, loss 0.0042\n",
      "Epoch 258, loss 0.0034\n",
      "Epoch 259, loss 0.0028\n",
      "Epoch 260, loss 0.0024\n",
      "Epoch 261, loss 0.0021\n",
      "Epoch 262, loss 0.0019\n",
      "Epoch 263, loss 0.0017\n",
      "Epoch 264, loss 0.0016\n",
      "Epoch 265, loss 0.0015\n",
      "Epoch 266, loss 0.0014\n",
      "Epoch 267, loss 0.0013\n",
      "Epoch 268, loss 0.0012\n",
      "Epoch 269, loss 0.0012\n",
      "Epoch 270, loss 0.0011\n",
      "Epoch 271, loss 0.0011\n",
      "Epoch 272, loss 0.0010\n",
      "Epoch 273, loss 0.0013\n",
      "Epoch 274, loss 0.0011\n",
      "Epoch 275, loss 0.0010\n",
      "Epoch 276, loss 0.0010\n",
      "Epoch 277, loss 0.0010\n",
      "Epoch 278, loss 0.0010\n",
      "Epoch 279, loss 0.0010\n",
      "Epoch 280, loss 0.0010\n",
      "Epoch 281, loss 0.0011\n",
      "Epoch 282, loss 0.0012\n",
      "Epoch 283, loss 0.0013\n",
      "Epoch 284, loss 0.0016\n",
      "Epoch 285, loss 0.0017\n",
      "Epoch 286, loss 0.0018\n",
      "Epoch 287, loss 0.0021\n",
      "Epoch 288, loss 0.0019\n",
      "Epoch 289, loss 0.0024\n",
      "Epoch 290, loss 0.0011\n",
      "Epoch 291, loss 0.0012\n",
      "Epoch 292, loss 0.0014\n",
      "Epoch 293, loss 0.0018\n",
      "Epoch 294, loss 0.0013\n",
      "Epoch 295, loss 0.0018\n",
      "Epoch 296, loss 0.0011\n",
      "Epoch 297, loss 0.0013\n",
      "Epoch 298, loss 0.0023\n",
      "Epoch 299, loss 0.0008\n",
      "Epoch 300, loss 0.0009\n",
      "Epoch 301, loss 0.0011\n",
      "Epoch 302, loss 0.0016\n",
      "Epoch 303, loss 0.0007\n",
      "Epoch 304, loss 0.0010\n",
      "Epoch 305, loss 0.0019\n",
      "Epoch 306, loss 0.0006\n",
      "Epoch 307, loss 0.0009\n",
      "Epoch 308, loss 0.0021\n",
      "Epoch 309, loss 0.0014\n",
      "Epoch 310, loss 0.0010\n",
      "Epoch 311, loss 0.0007\n",
      "Epoch 312, loss 0.0017\n",
      "Epoch 313, loss 0.0008\n",
      "Epoch 314, loss 0.0019\n",
      "Epoch 315, loss 0.0018\n",
      "Epoch 316, loss 0.0031\n",
      "Epoch 317, loss 0.8799\n",
      "Epoch 318, loss 0.0552\n",
      "Epoch 319, loss 0.0224\n",
      "Epoch 320, loss 0.0159\n",
      "Epoch 321, loss 0.0062\n",
      "Epoch 322, loss 0.0045\n",
      "Epoch 323, loss 0.0036\n",
      "Epoch 324, loss 0.0030\n",
      "Epoch 325, loss 0.0025\n",
      "Epoch 326, loss 0.0022\n",
      "Epoch 327, loss 0.0019\n",
      "Epoch 328, loss 0.0017\n",
      "Epoch 329, loss 0.0016\n",
      "Epoch 330, loss 0.0014\n",
      "Epoch 331, loss 0.0013\n",
      "Epoch 332, loss 0.0012\n",
      "Epoch 333, loss 0.0011\n",
      "Epoch 334, loss 0.0011\n",
      "Epoch 335, loss 0.0010\n",
      "Epoch 336, loss 0.0009\n",
      "Epoch 337, loss 0.0009\n",
      "Epoch 338, loss 0.0008\n",
      "Epoch 339, loss 0.0008\n",
      "Epoch 340, loss 0.0008\n",
      "Epoch 341, loss 0.0007\n",
      "Epoch 342, loss 0.0007\n",
      "Epoch 343, loss 0.0007\n",
      "Epoch 344, loss 0.0006\n",
      "Epoch 345, loss 0.0006\n",
      "Epoch 346, loss 0.0006\n",
      "Epoch 347, loss 0.0006\n",
      "Epoch 348, loss 0.0005\n",
      "Epoch 349, loss 0.0005\n",
      "Epoch 350, loss 0.0005\n",
      "Epoch 351, loss 0.0005\n",
      "Epoch 352, loss 0.0005\n",
      "Epoch 353, loss 0.0005\n",
      "Epoch 354, loss 0.0005\n",
      "Epoch 355, loss 0.0004\n",
      "Epoch 356, loss 0.0004\n",
      "Epoch 357, loss 0.0004\n",
      "Epoch 358, loss 0.0004\n",
      "Epoch 359, loss 0.0004\n",
      "Epoch 360, loss 0.0004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361, loss 0.0004\n",
      "Epoch 362, loss 0.0004\n",
      "Epoch 363, loss 0.0004\n",
      "Epoch 364, loss 0.0004\n",
      "Epoch 365, loss 0.0004\n",
      "Epoch 366, loss 0.0004\n",
      "Epoch 367, loss 0.0005\n",
      "Epoch 368, loss 0.0005\n",
      "Epoch 369, loss 0.0006\n",
      "Epoch 370, loss 0.0008\n",
      "Epoch 371, loss 0.0009\n",
      "Epoch 372, loss 0.0012\n",
      "Epoch 373, loss 0.0005\n",
      "Epoch 374, loss 0.0006\n",
      "Epoch 375, loss 0.0008\n",
      "Epoch 376, loss 0.0015\n",
      "Epoch 377, loss 0.0004\n",
      "Epoch 378, loss 0.0005\n",
      "Epoch 379, loss 0.0007\n",
      "Epoch 380, loss 0.0008\n",
      "Epoch 381, loss 0.0004\n",
      "Epoch 382, loss 0.0006\n",
      "Epoch 383, loss 0.0012\n",
      "Epoch 384, loss 0.0003\n",
      "Epoch 385, loss 0.0004\n",
      "Epoch 386, loss 0.0006\n",
      "Epoch 387, loss 0.0005\n",
      "Epoch 388, loss 0.0011\n",
      "Epoch 389, loss 0.0003\n",
      "Epoch 390, loss 0.0005\n",
      "Epoch 391, loss 0.0012\n",
      "Epoch 392, loss 0.0011\n",
      "Epoch 393, loss 0.0014\n",
      "Epoch 394, loss 0.4090\n",
      "Epoch 395, loss 0.0131\n",
      "Epoch 396, loss 0.0029\n",
      "Epoch 397, loss 0.0023\n",
      "Epoch 398, loss 0.0020\n",
      "Epoch 399, loss 0.0017\n",
      "Epoch 400, loss 0.0015\n",
      "Epoch 401, loss 0.0014\n",
      "Epoch 402, loss 0.0012\n",
      "Epoch 403, loss 0.0011\n",
      "Epoch 404, loss 0.0010\n",
      "Epoch 405, loss 0.0010\n",
      "Epoch 406, loss 0.0009\n",
      "Epoch 407, loss 0.0008\n",
      "Epoch 408, loss 0.0008\n",
      "Epoch 409, loss 0.0007\n",
      "Epoch 410, loss 0.0007\n",
      "Epoch 411, loss 0.0006\n",
      "Epoch 412, loss 0.0006\n",
      "Epoch 413, loss 0.0006\n",
      "Epoch 414, loss 0.0005\n",
      "Epoch 415, loss 0.0005\n",
      "Epoch 416, loss 0.0005\n",
      "Epoch 417, loss 0.0005\n",
      "Epoch 418, loss 0.0004\n",
      "Epoch 419, loss 0.0004\n",
      "Epoch 420, loss 0.0004\n",
      "Epoch 421, loss 0.0004\n",
      "Epoch 422, loss 0.0004\n",
      "Epoch 423, loss 0.0003\n",
      "Epoch 424, loss 0.0003\n",
      "Epoch 425, loss 0.0003\n",
      "Epoch 426, loss 0.0003\n",
      "Epoch 427, loss 0.0003\n",
      "Epoch 428, loss 0.0003\n",
      "Epoch 429, loss 0.0003\n",
      "Epoch 430, loss 0.0003\n",
      "Epoch 431, loss 0.0003\n",
      "Epoch 432, loss 0.0002\n",
      "Epoch 433, loss 0.0002\n",
      "Epoch 434, loss 0.0002\n",
      "Epoch 435, loss 0.0002\n",
      "Epoch 436, loss 0.0002\n",
      "Epoch 437, loss 0.0002\n",
      "Epoch 438, loss 0.0002\n",
      "Epoch 439, loss 0.0002\n",
      "Epoch 440, loss 0.0002\n",
      "Epoch 441, loss 0.0002\n",
      "Epoch 442, loss 0.0002\n",
      "Epoch 443, loss 0.0002\n",
      "Epoch 444, loss 0.0002\n",
      "Epoch 445, loss 0.0002\n",
      "Epoch 446, loss 0.0002\n",
      "Epoch 447, loss 0.0002\n",
      "Epoch 448, loss 0.0002\n",
      "Epoch 449, loss 0.0002\n",
      "Epoch 450, loss 0.0002\n",
      "Epoch 451, loss 0.0002\n",
      "Epoch 452, loss 0.0002\n",
      "Epoch 453, loss 0.0002\n",
      "Epoch 454, loss 0.0002\n",
      "Epoch 455, loss 0.0002\n",
      "Epoch 456, loss 0.0002\n",
      "Epoch 457, loss 0.0002\n",
      "Epoch 458, loss 0.0002\n",
      "Epoch 459, loss 0.0003\n",
      "Epoch 460, loss 0.0004\n",
      "Epoch 461, loss 0.0008\n",
      "Epoch 462, loss 0.0002\n",
      "Epoch 463, loss 0.0003\n",
      "Epoch 464, loss 0.0005\n",
      "Epoch 465, loss 0.0002\n",
      "Epoch 466, loss 0.0004\n",
      "Epoch 467, loss 0.0004\n",
      "Epoch 468, loss 0.0002\n",
      "Epoch 469, loss 0.0003\n",
      "Epoch 470, loss 0.0004\n",
      "Epoch 471, loss 0.0002\n",
      "Epoch 472, loss 0.0002\n",
      "Epoch 473, loss 0.0012\n",
      "Epoch 474, loss 0.7622\n",
      "Epoch 475, loss 0.0434\n",
      "Epoch 476, loss 0.0098\n",
      "Epoch 477, loss 0.0028\n",
      "Epoch 478, loss 0.0024\n",
      "Epoch 479, loss 0.0021\n",
      "Epoch 480, loss 0.0019\n",
      "Epoch 481, loss 0.0017\n",
      "Epoch 482, loss 0.0015\n",
      "Epoch 483, loss 0.0014\n",
      "Epoch 484, loss 0.0013\n",
      "Epoch 485, loss 0.0012\n",
      "Epoch 486, loss 0.0011\n",
      "Epoch 487, loss 0.0010\n",
      "Epoch 488, loss 0.0009\n",
      "Epoch 489, loss 0.0009\n",
      "Epoch 490, loss 0.0008\n",
      "Epoch 491, loss 0.0008\n",
      "Epoch 492, loss 0.0007\n",
      "Epoch 493, loss 0.0007\n",
      "Epoch 494, loss 0.0006\n",
      "Epoch 495, loss 0.0006\n",
      "Epoch 496, loss 0.0006\n",
      "Epoch 497, loss 0.0005\n",
      "Epoch 498, loss 0.0005\n",
      "Epoch 499, loss 0.0005\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "#model = Classifier(1, 256, trainset.num_classes)\n",
    "model = Classifier(1, 256, 4)\n",
    "model.cuda()\n",
    "loss_func = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr = initial_lr)\n",
    "# optimizer = optim.SGD(model.parameters(), lr = initial_lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "\n",
    "labels_shuffled = torch.LongTensor(labels_shuffled).cuda()\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for iter, bg in enumerate(trainset_shuffled):\n",
    "        prediction=torch.zeros(1,4,dtype=torch.float64).cuda()\n",
    "        prediction[0] = model(bg)\n",
    "\n",
    "        loss = loss_func(prediction, labels_shuffled[iter])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= (iter + 1)\n",
    "    print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    \n",
    "#     if (epoch%5==0):\n",
    "#         model.eval()\n",
    "#         eval_bg = dgl.batch(trainset_shuffled)\n",
    "#         eval_labels = torch.tensor(labels_shuffled).float().view(-1, 1)\n",
    "#         probs_Y = torch.softmax(model(eval_bg), 1)\n",
    "#         argmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n",
    "\n",
    "#         print('Accuracy of argmax predictions on the test set: {:4f}%'.format(\n",
    "#             (eval_labels == argmax_Y.float()).sum().item() / len(eval_labels) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('cross entropy averaged over minibatches')\n",
    "plt.plot(epoch_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.layers[0].apply_mod.linear.weight.size())\n",
    "print(model.layers[1].apply_mod.linear.weight.size())\n",
    "model.classify.weight.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Testset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = []\n",
    "test_labels = []\n",
    "test_dir = 'test_data'\n",
    "\n",
    "testing_idx_1=[]\n",
    "testing_idx_2=[]\n",
    "testing_idx_3=[]\n",
    "testing_idx_4=[]\n",
    "for i in range(4,65):\n",
    "    if i not in training_idx_1:\n",
    "        testing_idx_1.append(i)\n",
    "    if i not in training_idx_2:\n",
    "        testing_idx_2.append(i)\n",
    "    if i not in training_idx_3:\n",
    "        testing_idx_3.append(i)\n",
    "    if i not in training_idx_4:\n",
    "        testing_idx_4.append(i)\n",
    "        \n",
    "# print(testing_idx_1)\n",
    "# print(training_idx_1)\n",
    "# print(testing_idx_2)\n",
    "# print(training_idx_2)\n",
    "# print(testing_idx_3)\n",
    "# print(training_idx_3)\n",
    "# print(testing_idx_4)\n",
    "# print(training_idx_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sample Nodes and Edges for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove redundant edges from edge list based on sampled node list\n",
    "def remove_edges(node_list,edge_list):\n",
    "    \n",
    "    edge_list_keep = []\n",
    "    for i in edge_list:\n",
    "        cnt=0\n",
    "        for j in i:\n",
    "            if [j] in node_list:\n",
    "                cnt=cnt+1\n",
    "            if cnt==2:\n",
    "                edge_list_keep.append(i)\n",
    "                \n",
    "    return edge_list_keep\n",
    "\n",
    "#Map edge_list_keep to new node labels\n",
    "def map_edge_list_keep(edge_list_keep,node_list_keep):\n",
    "    \n",
    "    edge_list_keep_mapped = []\n",
    "    for i in edge_list_keep:\n",
    "        edge_list_keep_mapped.append([node_list_keep.index([i[0]]),node_list_keep.index([i[1]])])\n",
    "\n",
    "    return edge_list_keep_mapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Percentage Keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_keep = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "for idx in range(len(testing_idx_1)):\n",
    "    node_list=[]\n",
    "    edge_list=[]\n",
    "    label_list=[]\n",
    "    node_list2=[]\n",
    "    edge_list2=[]\n",
    "    label_list2=[]\n",
    "    node_list3=[]\n",
    "    edge_list3=[]\n",
    "    label_list3=[]\n",
    "    node_list4=[]\n",
    "    edge_list4=[]\n",
    "    label_list4=[]\n",
    "    for j in [\"node_list\",\"edge_list\",\"graph_label\"]:\n",
    "        filename = \"rca_\"+str(testing_idx_1[idx])+\"bit\"+j+'.csv'\n",
    "        filename2 = \"cla_\"+str(testing_idx_2[idx])+\"bit\"+j+'.csv'\n",
    "        filename3 = \"csa_\"+str(testing_idx_3[idx])+\"bit\"+j+'.csv'\n",
    "        filename4 = \"CSkipA_\"+str(testing_idx_4[idx])+\"bit\"+j+'.csv'\n",
    "        \n",
    "        if(filename.find(\"node_list\")>=0):\n",
    "            with open(test_dir+'/'+filename, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                node_list = list(reader)\n",
    "                \n",
    "        if(filename.find(\"edge_list\")>=0):\n",
    "            with open(test_dir+'/'+filename, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                edge_list = list(reader)\n",
    "        if(filename.find(\"graph_label\")>=0):\n",
    "            with open(test_dir+'/'+filename, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                label_list = list(reader)\n",
    "        if(filename.find(\"gate_type\")>=0):\n",
    "            with open(test_dir+'/'+filename, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                gate_type = list(reader)\n",
    "        \n",
    "        if(filename2.find(\"node_list\")>=0):\n",
    "            with open(test_dir+'/'+filename2, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                node_list2 = list(reader)\n",
    "                \n",
    "        if(filename2.find(\"edge_list\")>=0):\n",
    "            with open(test_dir+'/'+filename2, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                edge_list2 = list(reader)\n",
    "        if(filename2.find(\"graph_label\")>=0):\n",
    "            with open(test_dir+'/'+filename2, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                label_list2 = list(reader)\n",
    "        if(filename2.find(\"gate_type\")>=0):\n",
    "            with open(test_dir+'/'+filename2, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                gate_type2 = list(reader)\n",
    "        if(filename3.find(\"node_list\")>=0):\n",
    "            with open(test_dir+'/'+filename3, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                node_list3 = list(reader)\n",
    "                \n",
    "        if(filename3.find(\"edge_list\")>=0):\n",
    "            with open(test_dir+'/'+filename3, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                edge_list3 = list(reader)\n",
    "        if(filename3.find(\"graph_label\")>=0):\n",
    "            with open(test_dir+'/'+filename3, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                label_list3 = list(reader)\n",
    "        if(filename3.find(\"gate_type\")>=0):\n",
    "            with open(test_dir+'/'+filename3, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                gate_type3 = list(reader)\n",
    "        if(filename4.find(\"node_list\")>=0):\n",
    "            with open(dir+'/'+filename4, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                node_list4 = list(reader)\n",
    "                \n",
    "        if(filename4.find(\"edge_list\")>=0):\n",
    "            with open(dir+'/'+filename4, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                edge_list4 = list(reader)\n",
    "        if(filename4.find(\"graph_label\")>=0):\n",
    "            with open(dir+'/'+filename4, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                label_list4 = list(reader)\n",
    "        if(filename4.find(\"gate_type\")>=0):\n",
    "            with open(dir+'/'+filename4, 'rt') as fh:\n",
    "                reader=csv.reader(fh)\n",
    "                gate_type4 = list(reader)\n",
    "    \n",
    "    #randomly sample nodes and edges from a list\n",
    "    \n",
    "    #Sample nodes, remove edges accordingly:\n",
    "    seed = 1\n",
    "    random.seed(seed)\n",
    "    node_list_keep = random.sample(node_list,int(len(node_list)*pct_keep))\n",
    "    edge_list_keep = remove_edges(node_list_keep,edge_list)\n",
    "    edge_list_keep = map_edge_list_keep(edge_list_keep,node_list_keep)\n",
    "#     node_list_keep = node_list\n",
    "#     edge_list_keep = random.sample(edge_list,int(len(edge_list)*pct_keep))\n",
    "    random.seed(seed)\n",
    "    node_list2_keep = random.sample(node_list2,int(len(node_list2)*pct_keep))\n",
    "    edge_list2_keep = remove_edges(node_list2_keep,edge_list2)\n",
    "    edge_list2_keep = map_edge_list_keep(edge_list2_keep,node_list2_keep)\n",
    "#     node_list2_keep = node_list2\n",
    "#     edge_list2_keep = random.sample(edge_list2,int(len(edge_list2)*pct_keep))\n",
    "    random.seed(seed)\n",
    "    node_list3_keep = random.sample(node_list3,int(len(node_list3)*pct_keep))\n",
    "    edge_list3_keep = remove_edges(node_list3_keep,edge_list3)\n",
    "    edge_list3_keep = map_edge_list_keep(edge_list3_keep,node_list3_keep)\n",
    "#     node_list3_keep = node_list3\n",
    "#     edge_list3_keep = random.sample(edge_list3,int(len(edge_list3)*pct_keep))\n",
    "    random.seed(seed)\n",
    "    node_list4_keep = random.sample(node_list4,int(len(node_list4)*pct_keep))\n",
    "    edge_list4_keep = remove_edges(node_list4_keep,edge_list4)\n",
    "    edge_list4_keep = map_edge_list_keep(edge_list4_keep,node_list4_keep)\n",
    "#     node_list4_keep = node_list4\n",
    "#     edge_list4_keep = random.sample(edge_list4,int(len(edge_list4)*pct_keep))\n",
    "    \n",
    "    #create dgl graph\n",
    "    g=build_circuit_graph_undirected(node_list_keep,edge_list_keep)\n",
    "    testset.append(g)\n",
    "    test_labels.append(label_list[0])\n",
    "    g2=build_circuit_graph_undirected(node_list2_keep,edge_list2_keep)\n",
    "    testset.append(g2)\n",
    "    test_labels.append(label_list2[0])\n",
    "    g3=build_circuit_graph_undirected(node_list3_keep,edge_list3_keep)\n",
    "    testset.append(g3)\n",
    "    test_labels.append(label_list3[0])\n",
    "    g4=build_circuit_graph_undirected(node_list4_keep,edge_list4_keep)\n",
    "    testset.append(g4)\n",
    "    test_labels.append(label_list4[0])\n",
    "\n",
    "for i in test_labels:\n",
    "    i[0] = int(i[0])\n",
    "\n",
    "# print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##apply random shuffle on the testset    \n",
    "np.random.seed(0)\n",
    "randomize = np.arange(len(testset))\n",
    "np.random.shuffle(randomize)\n",
    "testset_shuffled=[]\n",
    "test_labels_shuffled=[]\n",
    "for i in range (len(randomize)):\n",
    "    test_labels_shuffled.append(test_labels[randomize[i]])\n",
    "    testset_shuffled.append(testset[randomize[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of sampled predictions on the test set: 93.2927%\n",
      "Accuracy of argmax predictions on the test set: 94.512195%\n",
      "tensor([2.7761e-12, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([8.3150e-01, 1.9573e-13, 4.9557e-07, 1.6850e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([4.1059e-13, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.7324e-08, 1.8610e-01, 5.9922e-18, 8.1390e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([7.1578e-13, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([3.7724e-14, 9.9926e-01, 1.8354e-24, 7.4284e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([2.3310e-14, 9.9934e-01, 1.2545e-24, 6.6401e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([9.6565e-01, 3.2609e-15, 9.4391e-07, 3.4353e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([3.6853e-04, 0.0000e+00, 9.9963e-01, 6.1106e-32], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.2162e-14, 9.9930e-01, 1.1550e-24, 6.9942e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([9.9618e-01, 1.0481e-17, 2.6491e-06, 3.8159e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([4.9841e-14, 9.9919e-01, 2.5195e-24, 8.0849e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([3.1149e-14, 9.9919e-01, 1.7379e-24, 8.1224e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([1.2555e-06, 2.5498e-04, 3.1949e-15, 9.9974e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([1.1282e-09, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([9.1840e-01, 2.5254e-14, 7.3555e-07, 8.1602e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.3027e-02, 6.9420e-09, 6.2662e-10, 9.8697e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([5.7014e-05, 4.7485e-07, 6.0121e-13, 9.9994e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.6666e-01, 1.7231e-11, 5.7920e-08, 7.3334e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([6.7768e-08, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([1.0326e-14, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.3052e-04, 7.6699e-08, 3.7323e-12, 9.9977e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([5.3489e-04, 6.0493e-07, 8.1614e-12, 9.9946e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.2555e-06, 2.5498e-04, 3.1949e-15, 9.9974e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.3052e-04, 7.6699e-08, 3.7322e-12, 9.9977e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([1.1716e-13, 9.9876e-01, 6.1723e-24, 1.2428e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([2.3911e-03, 3.1018e-09, 7.0494e-11, 9.9761e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.1538e-05, 0.0000e+00, 9.9998e-01, 2.1365e-36], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([9.6384e-01, 2.6604e-15, 1.0169e-06, 3.6156e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.3439e-14, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([5.4333e-14, 9.9934e-01, 3.1620e-24, 6.6131e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([1.8973e-01, 8.7521e-11, 3.5139e-08, 8.1027e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([2.3911e-03, 3.1018e-09, 7.0494e-11, 9.9761e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.2244e-13, 9.9846e-01, 1.1093e-23, 1.5409e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([2.3052e-04, 7.6699e-08, 3.7323e-12, 9.9977e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.9957e-01, 2.7809e-19, 4.3293e-06, 4.2224e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.1365e-07, 1.8320e-02, 7.1788e-17, 9.8168e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([1.5518e-06, 8.4596e-05, 5.0530e-15, 9.9991e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.6831e-05, 1.8336e-07, 1.2235e-12, 9.9990e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.2736e-14, 9.9851e-01, 4.8009e-24, 1.4945e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([4.4457e-11, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([9.5406e-01, 1.1532e-14, 8.2122e-07, 4.5938e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([3.9371e-14, 9.9909e-01, 2.1035e-24, 9.0577e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([2.4794e-06, 0.0000e+00, 1.0000e+00, 3.1759e-40], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([5.9032e-06, 0.0000e+00, 9.9999e-01, 5.9944e-39], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([9.9949e-01, 2.4714e-19, 4.4538e-06, 5.0407e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([4.6168e-11, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.1536e-14, 9.9945e-01, 1.1909e-24, 5.4965e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([3.1369e-14, 9.9913e-01, 1.5711e-24, 8.6599e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([9.9477e-01, 9.9414e-17, 1.6911e-06, 5.2297e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.1365e-07, 1.8320e-02, 7.1788e-17, 9.8168e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([1.4104e-08, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.8007e-04, 8.4558e-08, 4.0174e-12, 9.9972e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.6676e-01, 2.6306e-15, 1.1077e-06, 3.3242e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([4.2882e-06, 2.7392e-05, 1.5590e-14, 9.9997e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([3.9815e-14, 9.9910e-01, 2.0309e-24, 8.9730e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([4.0527e-07, 0.0000e+00, 1.0000e+00, 2.1440e-43], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([8.0027e-07, 4.3237e-04, 1.4453e-15, 9.9957e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([8.3696e-09, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([5.7978e-01, 5.8037e-12, 1.7224e-07, 4.2022e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([9.1332e-01, 3.0734e-14, 6.5043e-07, 8.6681e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([6.8012e-14, 9.9902e-01, 3.2807e-24, 9.7519e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([7.9909e-14, 9.9875e-01, 4.4377e-24, 1.2481e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([4.2882e-06, 2.7393e-05, 1.5590e-14, 9.9997e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.3126e-12, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.9584e-17, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([1.2555e-06, 2.5498e-04, 3.1949e-15, 9.9974e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([8.1340e-01, 0.0000e+00, 1.8660e-01, 1.5180e-16], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.8597e-14, 9.9928e-01, 1.4509e-24, 7.2483e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([5.3468e-15, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.8875e-14, 9.9926e-01, 1.4818e-24, 7.4088e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([9.9872e-01, 2.9988e-18, 2.6367e-06, 1.2768e-03], device='cuda:0',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([7.3326e-06, 1.9317e-05, 3.0791e-14, 9.9997e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.6831e-05, 1.8336e-07, 1.2235e-12, 9.9990e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.8963e-01, 2.1790e-16, 1.7577e-06, 1.0364e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([8.2086e-08, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([3.9253e-14, 9.9891e-01, 1.9537e-24, 1.0903e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([4.4592e-14, 9.9904e-01, 2.0750e-24, 9.5613e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([2.8286e-14, 9.9935e-01, 1.5605e-24, 6.4683e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([5.7014e-05, 4.7485e-07, 6.0121e-13, 9.9994e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([8.8756e-01, 4.6793e-14, 6.0203e-07, 1.1244e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([2.1107e-01, 7.8048e-11, 3.1227e-08, 7.8893e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([6.6895e-01, 7.1645e-13, 3.2926e-07, 3.3105e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([4.2245e-14, 9.9933e-01, 2.1601e-24, 6.7325e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([9.6804e-01, 1.8725e-15, 1.0862e-06, 3.1955e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([8.5043e-15, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([1.1365e-07, 1.8320e-02, 7.1788e-17, 9.8168e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([5.9632e-13, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.1304e-13, 9.9840e-01, 9.1100e-24, 1.5961e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([1.1365e-07, 1.8320e-02, 7.1788e-17, 9.8168e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([1.0477e-11, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([5.1205e-14, 9.9937e-01, 2.4535e-24, 6.2550e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([3.2588e-14, 9.9923e-01, 1.6635e-24, 7.6581e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([1.0111e-06, 4.8912e-03, 4.8185e-16, 9.9511e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.3911e-03, 3.1018e-09, 7.0494e-11, 9.9761e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.4417e-01, 5.6582e-15, 8.8780e-07, 5.5831e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.2105e-05, 0.0000e+00, 9.9999e-01, 2.3556e-36], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([5.7725e-14, 9.9912e-01, 3.0220e-24, 8.8214e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([8.0027e-07, 4.3237e-04, 1.4453e-15, 9.9957e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([1.8264e-14, 9.9936e-01, 9.8339e-25, 6.4290e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([2.0129e-05, 2.2845e-06, 1.6425e-13, 9.9998e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.2768e-13, 9.9867e-01, 1.4111e-23, 1.3300e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([9.9568e-01, 3.3269e-17, 2.1919e-06, 4.3158e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([9.9384e-01, 5.6244e-17, 2.0049e-06, 6.1617e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.9451e-06, 0.0000e+00, 1.0000e+00, 6.2891e-40], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([6.2668e-13, 9.9616e-01, 4.3610e-23, 3.8374e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([1.5518e-06, 8.4596e-05, 5.0530e-15, 9.9991e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.9969e-01, 1.2008e-19, 4.8771e-06, 3.0218e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([3.7622e-10, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.7324e-08, 1.8610e-01, 5.9922e-18, 8.1390e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.1596e-13, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([6.6733e-07, 4.2593e-04, 1.0683e-15, 9.9957e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.6827e-01, 2.9801e-15, 1.0756e-06, 3.1725e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([9.9715e-01, 7.8553e-18, 2.6112e-06, 2.8467e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([2.8720e-14, 9.9930e-01, 1.5082e-24, 6.9658e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([9.3486e-01, 1.6848e-14, 6.1302e-07, 6.5144e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([9.9842e-01, 1.0546e-17, 8.8655e-07, 1.5817e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([2.3545e-15, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.4010e-14, 9.9927e-01, 1.2146e-24, 7.3214e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([7.4914e-09, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([9.9830e-01, 3.2363e-18, 3.0681e-06, 1.6972e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.2308e-12, 9.9747e-01, 5.0366e-23, 2.5313e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([2.0920e-16, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([8.9261e-01, 1.2959e-13, 4.5664e-07, 1.0739e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([3.8929e-14, 9.9908e-01, 2.0692e-24, 9.1750e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([3.0641e-14, 9.9918e-01, 1.5187e-24, 8.1917e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([1.1659e-03, 0.0000e+00, 9.9883e-01, 1.7676e-29], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([9.6534e-01, 3.4082e-14, 5.0760e-07, 3.4663e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([6.6560e-01, 6.3186e-13, 2.7186e-07, 3.3440e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([2.5945e-16, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.4670e-14, 9.9927e-01, 1.2986e-24, 7.2926e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([3.8690e-07, 0.0000e+00, 1.0000e+00, 4.1198e-43], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([9.5496e-14, 9.9895e-01, 4.6306e-24, 1.0474e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([2.3554e-14, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([6.6733e-07, 4.2593e-04, 1.0683e-15, 9.9957e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([3.3804e-11, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([2.8007e-04, 8.4558e-08, 4.0174e-12, 9.9972e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([3.2772e-14, 9.9904e-01, 1.7656e-24, 9.5919e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([1.1314e-13, 9.9875e-01, 6.0054e-24, 1.2498e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([1.6607e-01, 1.1383e-10, 2.2611e-08, 8.3393e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.5518e-06, 8.4596e-05, 5.0530e-15, 9.9991e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([5.1683e-08, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([7.3325e-06, 1.9317e-05, 3.0791e-14, 9.9997e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.0129e-05, 2.2845e-06, 1.6425e-13, 9.9998e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([2.3911e-03, 3.1018e-09, 7.0494e-11, 9.9761e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([1.8488e-14, 9.9928e-01, 9.1045e-25, 7.2333e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([9.9744e-01, 1.8509e-17, 2.1774e-06, 2.5537e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([2.6044e-02, 1.9524e-09, 1.6603e-09, 9.7396e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([9.9863e-01, 1.9099e-18, 3.2348e-06, 1.3635e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([3.5879e-16, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([3.5411e-14, 9.9925e-01, 1.8620e-24, 7.5413e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([6.6733e-07, 4.2593e-04, 1.0683e-15, 9.9957e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.8649e-10, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([3.7309e-14, 9.9910e-01, 1.8442e-24, 8.9768e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([2.2161e-14, 9.9933e-01, 1.1058e-24, 6.6993e-04], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([3.3866e-12, 0.0000e+00, 1.0000e+00, 0.0000e+00], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([2.], device='cuda:0')\n",
      "tensor([1.5518e-06, 8.4596e-05, 5.0530e-15, 9.9991e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([1.4752e-13, 9.9792e-01, 6.8180e-24, 2.0805e-03], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([1.], device='cuda:0')\n",
      "tensor([9.8250e-01, 2.4173e-15, 8.9192e-07, 1.7495e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([9.9996e-01, 3.5395e-25, 3.3891e-05, 4.5651e-06], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.1948e-05, 3.9367e-06, 7.9144e-14, 9.9998e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([4.2882e-06, 2.7393e-05, 1.5590e-14, 9.9997e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n",
      "tensor([9.6660e-01, 7.9448e-15, 9.0350e-07, 3.3400e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([0.], device='cuda:0')\n",
      "tensor([1.2555e-06, 2.5498e-04, 3.1949e-15, 9.9974e-01], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>) tensor([3.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_bg = dgl.batch(testset_shuffled)\n",
    "test_labels = torch.tensor(test_labels_shuffled).float().view(-1, 1).cuda()\n",
    "probs_Y = torch.softmax(model(test_bg), 1)\n",
    "\n",
    "sampled_Y = torch.multinomial(probs_Y, 1)\n",
    "argmax_Y = torch.max(probs_Y, 1)[1].view(-1, 1)\n",
    "print('Accuracy of sampled predictions on the test set: {:.4f}%'.format(\n",
    "    (test_labels == sampled_Y.float()).sum().item() / len(test_labels) * 100))\n",
    "print('Accuracy of argmax predictions on the test set: {:4f}%'.format(\n",
    "    (test_labels == argmax_Y.float()).sum().item() / len(test_labels) * 100))\n",
    "\n",
    "zip(model(test_bg),(test_labels))\n",
    "for i1,i2 in zip(probs_Y,(test_labels)):\n",
    "    print(i1,i2)\n",
    "# print(torch.max(probs_Y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (test_labels != argmax_Y.float()).nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0484e-05, 1.1342e-07, 6.8599e-15, 9.9999e-01], device='cuda:0',\n",
       "        grad_fn=<SelectBackward>), tensor([3.], device='cuda:0'))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_Y[79],test_labels[79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsne\n",
    "\n",
    "#m = trainset[0].adjacency_matrix()\n",
    "m = model(test_bg).cpu().data.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the data using PCA...\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 164...\n",
      "Mean value of sigma: 24.190304\n",
      "Iteration 10: error is nan\n",
      "Iteration 20: error is nan\n",
      "Iteration 30: error is nan\n",
      "Iteration 40: error is nan\n",
      "Iteration 50: error is nan\n",
      "Iteration 60: error is nan\n",
      "Iteration 70: error is nan\n",
      "Iteration 80: error is nan\n",
      "Iteration 90: error is nan\n",
      "Iteration 100: error is nan\n",
      "Iteration 110: error is nan\n",
      "Iteration 120: error is nan\n",
      "Iteration 130: error is nan\n",
      "Iteration 140: error is nan\n",
      "Iteration 150: error is nan\n",
      "Iteration 160: error is nan\n",
      "Iteration 170: error is nan\n",
      "Iteration 180: error is nan\n",
      "Iteration 190: error is nan\n",
      "Iteration 200: error is nan\n",
      "Iteration 210: error is nan\n",
      "Iteration 220: error is nan\n",
      "Iteration 230: error is nan\n",
      "Iteration 240: error is nan\n",
      "Iteration 250: error is nan\n",
      "Iteration 260: error is nan\n",
      "Iteration 270: error is nan\n",
      "Iteration 280: error is nan\n",
      "Iteration 290: error is nan\n",
      "Iteration 300: error is nan\n",
      "Iteration 310: error is nan\n",
      "Iteration 320: error is nan\n",
      "Iteration 330: error is nan\n",
      "Iteration 340: error is nan\n",
      "Iteration 350: error is nan\n",
      "Iteration 360: error is nan\n",
      "Iteration 370: error is nan\n",
      "Iteration 380: error is nan\n",
      "Iteration 390: error is nan\n",
      "Iteration 400: error is nan\n",
      "Iteration 410: error is nan\n",
      "Iteration 420: error is nan\n",
      "Iteration 430: error is nan\n",
      "Iteration 440: error is nan\n",
      "Iteration 450: error is nan\n",
      "Iteration 460: error is nan\n",
      "Iteration 470: error is nan\n",
      "Iteration 480: error is nan\n",
      "Iteration 490: error is nan\n",
      "Iteration 500: error is nan\n",
      "Iteration 510: error is nan\n",
      "Iteration 520: error is nan\n",
      "Iteration 530: error is nan\n",
      "Iteration 540: error is nan\n",
      "Iteration 550: error is nan\n",
      "Iteration 560: error is nan\n",
      "Iteration 570: error is nan\n",
      "Iteration 580: error is nan\n",
      "Iteration 590: error is nan\n",
      "Iteration 600: error is nan\n",
      "Iteration 610: error is nan\n",
      "Iteration 620: error is nan\n",
      "Iteration 630: error is nan\n",
      "Iteration 640: error is nan\n",
      "Iteration 650: error is nan\n",
      "Iteration 660: error is nan\n",
      "Iteration 670: error is nan\n",
      "Iteration 680: error is nan\n",
      "Iteration 690: error is nan\n",
      "Iteration 700: error is nan\n",
      "Iteration 710: error is nan\n",
      "Iteration 720: error is nan\n",
      "Iteration 730: error is nan\n",
      "Iteration 740: error is nan\n",
      "Iteration 750: error is nan\n",
      "Iteration 760: error is nan\n",
      "Iteration 770: error is nan\n",
      "Iteration 780: error is nan\n",
      "Iteration 790: error is nan\n",
      "Iteration 800: error is nan\n",
      "Iteration 810: error is nan\n",
      "Iteration 820: error is nan\n",
      "Iteration 830: error is nan\n",
      "Iteration 840: error is nan\n",
      "Iteration 850: error is nan\n",
      "Iteration 860: error is nan\n",
      "Iteration 870: error is nan\n",
      "Iteration 880: error is nan\n",
      "Iteration 890: error is nan\n",
      "Iteration 900: error is nan\n",
      "Iteration 910: error is nan\n",
      "Iteration 920: error is nan\n",
      "Iteration 930: error is nan\n",
      "Iteration 940: error is nan\n",
      "Iteration 950: error is nan\n",
      "Iteration 960: error is nan\n",
      "Iteration 970: error is nan\n",
      "Iteration 980: error is nan\n",
      "Iteration 990: error is nan\n",
      "Iteration 1000: error is nan\n"
     ]
    }
   ],
   "source": [
    "Y = tsne.tsne(m, 2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAH8pJREFUeJzt3X+QXWWd5/H3hw7BakQIJLPFr3QnEtSQdcX0RKdcHWYBDThD3BXWUDcSDG4PQWZxra1arMyOFk5q1akZF1cCthpFEvnpOrajLkP4MVqWmHTkZ2AiTUxDCEpI4g9sTUjnu3+cp+F2n3u7b9++v7rzeVXd6nuf85z7POf29/a3zznPOY8iAjMzs2JHNbsDZmbWepwczMwsx8nBzMxynBzMzCzHycHMzHKcHMzMLMfJwczMcpwczMwsx8nBzMxyZjS7A5WYPXt2dHZ2NrsbNo1t3br1xYiY0+h2HdtWT5OJ6ymRHDo7O+nr62t2N2wakzRQ9HwpcD3QBnw5Ij49qu4xwNeBxcBe4AMRsVNSJ/AksD1VfTAirhyrXce21VNxXE/UlEgOZo0iqQ24ATgf2AVskdQbEU8UVbsC2B8RZ0haDnwG+EBa9nREvKWhnTarA59zMBtpCdAfETsi4iBwG7BsVJ1lwM3p+V3AuZLUwD6a1Z2Tg9lIpwLPFr3elcpK1omIQ8CvgZPSsnmSHpL0L5LeWe/OmtXLtDisdOpfnsru/btz5ZK45epbKLyz0IRe2RRVag9g9H3ty9V5HpgbEXslLQb+UdJZEfGbEStL3UA3wNy5c2vQZbPam/J7DuUSA0BEsOL/rGDjDzc2uFc2he0CTi96fRowOsBeqSNpBnA8sC8iDkTEXoCI2Ao8DZw5uoGI6ImIrojomjOn4QOkzCoy5ZNDucRQbM2taxrQE5smtgALJM2TNBNYDvSOqtMLrEzPLwbui4iQNCed0EbSfGABsKNB/TarqSmfHCoxsHeAGczgKq5qdlesxaVzCFcDd5MNS70jIrZJuk7SRanaV4CTJPUDHwOuTeXvAh6V9AjZieorI2JfY7fArDaalhwkLZW0XVK/pGvHX2MSToIhhriRGxGik0424kNNVlpEfC8izoyI10fE2lT2NxHRm57/ISIuiYgzImJJROxI5d+MiLMi4t9FxFsj4jvN3A6zyWhKcigaS34BsBC4VNLCat7rlFmnjF2hDbh0ZNEAA6xghROEmVkZzdpzqGQseUWe++Jz5RPEa4GrgDIDClewgvM4r5pmzcymtWYNZS01lvxt1b7Zc198Llc2gxkMMTTuuvfGvQhxwv4T2H/i/mq7YGY2rTRrz2HcseSSuiX1Serbs2fPhBvozoaRV9YTwa9m/Qod8kWuZmbQvOQw7ljyyY4FX8c6TuCEyioHMA+YCTpFXHWVRzWZ2ZGtWcmhkrHkk7af/SykgvPczwIDvHKN64033ogkzjrrrFp3ycxsSmhKcig3lrwebW1jG5G7+0GRA7w6Sn2UJ554Akls3OhRTWZ2ZGnadQ6lxpLXtT2CUzhl+MWrVgG3jr3uihUr8E03zexIckRcIT3sOZ4jCBZqYZYgAvhR5etLQhKdnZ3emzCzae2ISg7DtrGNUEoSa4H2ia0/MDDAqlWrnCDMbNo6IpPDsG1sIwrB6pWrJ7zuwYMHueaaa+rQKzOz5juik8OwdevWERGccEKFQ1+TvXv31qlHZmbN5eRQZP/+/SxcOLFbPB111FE+B2Fm046Twyjbtm1j9erKDzNFBAMDA3R3dztBmNm04eRQwvBhponsRQwODrJmjScVMrPpwclhDBPdi3jmmWfq2Bszs8ZxchjH8F5E8aOjo6NkXU8Wb2bThZNDFdauXUt7+8iLI9rb21m7tu4XepuZNYSTQxUKhQI9PT10dHQgiY6ODnp6eigUCs3umplZTTRrsp8pr1AoOBmY2bTlPQczM8txcjAzsxwnBzMzy3FyaJKNAxvp/G4nR915FJ3f7WTjgK+uNrPW4RPSTbBxYCPdW7sZHBoEYGBwgO6t3QAUOnyS28yaz3sOTbDm8TWvJIZhg0ODrHnct98ws9bg5NAEzwyWvs1GuXIzs0ZzcmiCue2lb7NRrtzMrNGcHJpg7aK1tLeNuv1GWztrF/n2G2bWGpwcmqDQUaBncQ8d7R0I0dHeQc/iHp+MNrOW4dFKTVLoKDgZmFnL8p6DmZnlODmYmVmOk8MU5quszaxefM5hivJV1mZWT95zmKLKXWW9YvMK70WY2aQ5OUxRY11NPbwX4QRRHUlLJW2X1C/p2hLLj5F0e1r+E0mdRcs+nsq3S3pPI/ttVktODlPUeFdT+15N1ZHUBtwAXAAsBC6VtHBUtSuA/RFxBvA54DNp3YXAcuAsYCmwLr2f2ZTj5DBFlbrKerRnBp/xSeuJWwL0R8SOiDgI3AYsG1VnGXBzen4XcK4kpfLbIuJARPwc6E/vZzblODlMUcVXWZdz4tEnsqpvFQODAwTBwOAAq/pWOUGM7VTg2aLXu1JZyToRcQj4NXBSheuaTQlODlNYoaPAzvfuZMOSDSXv1XQgDnDw8MER5QcPH+SyzZc5QZSnEmVRYZ1K1kVSt6Q+SX179uypootm9efkMA2Uu1fTS4deKln/MIdZsXkFs78920kibxdwetHr04Dd5epImgEcD+yrcF0ioiciuiKia86cOTXsulntODlME8N7EYcvOczO9+6s6FqHvQf3+jBT3hZggaR5kmaSnWDuHVWnF1iZnl8M3BcRkcqXp9FM84AFwOYG9duspiaVHCT9naR/lfSopG9JOqFoWckhfeMNE7TaOenok8atc/DwQa55+JoG9GZqSOcQrgbuBp4E7oiIbZKuk3RRqvYV4CRJ/cDHgGvTutuAO4AngP8HfCQihhq9DWa1MNk9h3uARRHxZuBnwMeh/JC+CocJWo1cf/b1HK2jx6239+BedKeYcdcMrtp6VQN61toi4nsRcWZEvD4i1qayv4mI3vT8DxFxSUScERFLImJH0bpr03pviIjvN2sbzCZrUskhIv45/acF8CDZMVYoP6SvkmGCViOFjgJf/eOvVrQHATAUQ9y440YnCDOr6TmHVcDwf0rlhvR5qF+DFToKvPi+F9mwZAMqOZgmr+fnPXXulZm1unGTg6RNkh4v8VhWVGcNcAgYPrM5qaF+6T093K+GCh0FbllyS0WHmYZiiBl3zfChJrMj2LjJISLOi4hFJR7fBpC0EvhzoJBGbED5IX0VDfVL7Xq4X40NH2YaHvI6lqF0HnX4UNMxdx3jUU1mR5DJjlZaCvwP4KKIKL5FaLkhfZUME7Q6Kh7yunr+6orXOxgHWbF5Bcd96zgnCbMjwGTnc/gCcAxwT3ZrGR6MiCvT0L/hIX2HKBrSJ2l4mGAbsD4N/7MmWLd4HZCdYxiKIdrU9soeQzkvHXqJVX2rAM8bYTad6dUjQa2rq6sr+vr6mt2NI8KMu2aMmyAAOto72PnenfXvUINI2hoRXY1u17Ft9TSZuPYV0jZC97zuiuoNDA74Tq9m05iTg42wbvE6zp1zbkV1h+/0+sHNH/SIJrNpxsnBcjads4kNSzZw7FHHVlQ/CF88ZzbNODlYSYWOAi+9/yU2LNlQ8RXWN+24yYeYzKYJJwcb0/AV1nFJEJfEmJMLBeGpSc2mCScHm5C1i9aOeQHdwOCAr642mwacHGxCCh0Frpx/5Zh1Rl9d7QRhNvU4OdiErVu8jtXzV1d8I78bd9yI7hSz/9Ezz5lNFU4OVpV1i9dxy5JbRkxNOp69L+/19KRmU8Rkb59hR7BCR2HELTQqvbp678G9dG/tfuU9zKz1eM/BaqbSq6sBBocGuWzzZd6DMGtRTg5WM8PnItrUVlH9wxz2YSazFuXkYDW1bvE6Dl18iA1LNjDzqJkVrbP34F7fgsOsxTg5WF0UOgqs71rPSTMru7p6+BYcbXe2OUmYtQAnB6ubQkeBF5dlV1dXeguOwxz2tRFmLcDJwRri+rOvr/gwE2QTEJlZ8zg5WENM9DBTJUNizax+nBysYYoPM413hXWb2tg4sJHO73Z6UiGzJnBysKYYvsL62LbSc0acM/scurd2MzA48MqkQis2r+C8B85rcE/NjkxODtY0hY4CL/2nl0ZcG9GmNlbPX03/7/oZHBrMrXPvnnudIMwawMnBmm742oi4JDh08SHWLV7HM4PPlK1/7557fRM/szpzcrCWNLd97pjL977sC+fM6snJwVrS2kVrx60ThKcmNasTJwdrSYWOAufOOXfcekGwcstKj2gyqzEnB2tZm87ZVFGCGIqhESOaXvvN1zpJmE2Sk4O1tE3nbGLDkg0VXzwH8LvDv+NDWz7kBGE2CU4O1vKGL56byNSkL8fLrHl8TZ17ZjZ9OTnYlDF6atLx5o0YGBzwuQizKjk52JRS6Ciw8707OXzJYW7+45vH3ZMYPhfRvbXbCcJsApwcbMoqdBS4cv6VFdUdHBoc9zCTpBMl3SPpqfRzVpl6K1OdpyStLCp/QNJ2SQ+nxx9NZHvMWomTg01p6xavq/iE9VhXXSfXAvdGxALg3vR6BEknAp8A3gYsAT4xKokUIuIt6fFChZth1nKcHGzKK77ba1wSdLR3lKw33lXXwDLg5vT8ZuB9Jeq8B7gnIvZFxH7gHmBpdT03a11ODjbtrF20lva29hFl7W3tlVx1/W8i4nmA9LPUYaFTgWeLXu9KZcO+mg4p/U9JlQ2tMmtBM5rdAbNaK3QUAFjz+BqeGXyGue1zWbtoLYWOAueddx6/+MUvSq12QoVvX+oPfgw3HRHPSToO+CbwQeDruTeQuoFugLlzx92bMWsKJweblgodhVeSRLFNmzaVrC/pV8CQpJMj4nlJJwOlzhnsAs4pen0a8ABARDyXfv5W0jfIzknkkkNE9AA9AF1dXTF6uVkr8GEls1f1AsOjj1YC3y5R527g3ZJmpRPR7wbuljRD0mwASUcDfw483oA+m9WFk4PZqz4NnC/pKeD89BpJXZK+DBAR+4BPAVvS47pUdgxZkngUeBh4DvhS4zfBrDYU0fp7tZL2AAMNbnY28GKD23TbzWu7IyLmNLrRcWK7mZ/HaK3Sl1bpB7ROX8bqR9VxPSWSQzNI6ouILrd9ZLTdilrp82iVvrRKP6B1+lKvfviwkpmZ5Tg5mJlZjpNDeT1u+4hquxW10ufRKn1plX5A6/SlLv3wOQczM8vxnoOZmeU4OZiZWY6TwyiSlqZ78vdLyt2yucZtnS7pfklPStom6ZpU/klJzxXNC3BhHfuwU9JjqZ2+VFbRvAaTbPcNRdv3sKTfSPpoI7e9Weo1b4SkYyTdnmL3J5I669UPSe2SvivpX1Psfrqo/uWS9hT178Nj9GHM79tY2yTp46l8u6T3VPqeteyHpPMlbU3foa2S/kPROlXN7zGJvnRK+n1RezcVrbM49bFf0uelCm4KGRF+pAfQBjwNzAdmAo8AC+vY3snAW9Pz44CfAQuBTwL/vUHbvBOYParss8C16fm1wGca8Ln/Auho5LY361HJ5wucCOxIP2el57PSsgeArhLrXAXclJ4vB26vVz+AduDPUp2ZwA+BC9Lry4EvVPh7H/P7Vm6b0vfkEbIr0+el92mr5js8yX6cDZySni8Cnitap+TvqY596QQeL/O+m4E/Ibtx5PeHf1djPbznMNISoD8idkTEQeA2snv810VEPB8RP03Pfws8ycjbPzdLJfMa1NK5wNMR0eir4JulXvNGFL/vXcC54/yHWHU/ImIwIu4HSN+Vn5LdhHAiKvm+ldumZcBtEXEgIn4O9Kf3q+Y7XHU/IuKhiNidyrcBr5F0TMWfQA37Uu4Nld1E8nUR8ePIMsXXqeA77eQw0nj36q+btGt4NvCTVHS1pEclra/HYZ0iAfxz2iXuTmWVzGtQS8uBW4teN2rbm6Ve80a8sk5EHAJ+DYw1RV4t+oGkE4C/IJs9b9j70+/wLkmnl2m/ku9buW0qt2413+HJ9KPY+4GHIuJAUdlE5/eYbF/mSXpI0r9IemdR/V3jvGeOk8NIY92rv36NSq8lu///RyPiN8CNwOuBtwDPA39fx+bfERFvBS4APiLpXXVsK0fSTOAi4M5U1MhtrxtJmyQ9XuJR6Z7oePNG/FvgnenxwTHW+WYd+4GkGWSJ/fMRsSMVfwfojIg3A5t49b/cCb33OHUmWj6WyfQjWyidBXwG+Mui5eV+T/Xqy/PA3Ig4G/gY8A1Jr6vwPXM8n8NIu4Di/3JOA3aXqVsTym7v/E1gY0T8X4CI+GXR8i8B/1Sv9od3iSPiBUnfItut/aXGn9egVi4Afjq8zY3c9nqKiPPKLZNUyedbzbwRw/G7K/3RPh44Ix1KqHk/kh7gqYj438MFEbG3aPmXyP5ollLJ963UNu0bZ92Jfocn0w8knQZ8C7gsIp4eXmGM31Nd+pJ+zwdSm1slPQ2cmeoXH/Kr6O+a9xxG2gIskDQv/Ue7nOwe/3WRdjO/AjwZEf9QVH5yUbX/SJ3mBZB0rLJZy5B0LNncBI9T2bwGtXIpRYeUGrXtTVaveSOK3/di4L5yiWGy/Ujt/y3ZH6aPFq8w6nd4Edm5tFIq+b6V26ZeYHkauTMPWEB20rWa73DV/UiH1L4LfDwiflT0GVQ7v8dk+jJHUltqc376THakQ4a/lfT29DfnMir5Tk/kTPqR8AAuJBs19DSwps5t/Xuy3bvhOQAeTu3fAjyWynuBk+vU/nyy0RCPkJ1MW5PKTyI7fvxU+nlindpvB/YCxxeVNWTbmxxjJT9foAv4clG9VWQnWvuBD6WyY4Gt6fPZBlwPtKVlryE7PNdP9odyfh37cVqK3SeLYvfDadn/Sn17BLgfeOMYfch934DrgIvG2yZgTVpvO0Wjb6r5DlfbD+Cvgd8VfQYPk527Kft7qmNf3l/0uf8U+Iui9+wiS05PA18g3R1jrEdVt8+QtJ4sE74QEYtKLFf6MC4EBoHLI43KUTZO+q9T1b+NiHLHI80azrFtlqn2sNLXGHtY3QVkuzQLyCZSvxGyi26ATwBvIzv+9olpOhrFpq6v4dg2qy45RMQPSCdjylgGfD0yDwInpOOQ1YzdNmsYx7ZZpl4npGs5BtmslTi27YhQr6Gskx6DnC7I6gY49thjF7/xjW+sXe/MRtm6deuLUdlcu45tmzImENc59UoO5cbqjjdm+hUR0UOaxKKrqyv6+vrq0U8zACRVeusOx7ZNGROI65x6HVbqBS5T5u3AryMba1t2zLTZFOHYtiNCVXsOkm4l+y9ptqRdZKM0jgaIiJuA75EN9esnG+73obRsn6RPkV3oAXBdRIx18s+soRzbZpmqkkNEXDrO8gA+UmbZemB9Ne2a1Ztj2yzj22eYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5VSdHCQtlbRdUr+ka0ss/5ykh9PjZ5J+VbRsqGhZb7V9MKs1x7VZptppQtuAG4DzySZW3yKpNyKeGK4TEf+tqP5fAWcXvcXvI+It1XXZrD4c12avqnbPYQnQHxE7IuIgcBuwbIz6lwK3VtmWWaM4rs2SapPDqcCzRa93pbIcSR3APOC+ouLXSOqT9KCk91XZB7Nac1ybJVUdVgJUoizK1F0O3BURQ0VlcyNit6T5wH2SHouIp0c0IHUD3QBz586tsptmE1L3uAbHtk0N1e457AJOL3p9GrC7TN3ljNr1jojd6ecO4AFGHrcdrtMTEV0R0TVnzpwqu2k2IXWP67TcsW0tr9rksAVYIGmepJlkX5Tc6AxJbwBmAT8uKpsl6Zj0fDbwDuCJ0euaNYHj2iyp6rBSRBySdDVwN9AGrI+IbZKuA/oiYvgLdSlwW0QU75q/CfiipMNkyenTxaNBzJrFcW32Ko2M79bU1dUVfX19ze6GTWOStkZEV6PbdWxbPU0mrn2FtJmZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVlO1clB0lJJ2yX1S7q2xPLLJe2R9HB6fLho2UpJT6XHymr7YFYPjm2zKqcJldQG3ACcTzYp+xZJvSWmRbw9Iq4ete6JwCeALiCArWnd/dX0xayWHNtmmWr3HJYA/RGxIyIOArcByypc9z3APRGxL31p7gGWVtkPs1pzbJtRfXI4FXi26PWuVDba+yU9KukuSadPZF1J3ZL6JPXt2bOnym6aTZhj24zqk4NKlMWo198BOiPizcAm4OYJrEtE9EREV0R0zZkzp8pumk2YY9uM6pPDLuD0otenAbuLK0TE3og4kF5+CVhc6bpmTeTYNqP65LAFWCBpnqSZwHKgt7iCpJOLXl4EPJme3w28W9IsSbOAd6cys1bg2DajytFKEXFI0tVkgd8GrI+IbZKuA/oiohf4r5IuAg4B+4DL07r7JH2K7EsIcF1E7JvkdpjVhGPbLKOI3CHRltPV1RV9fX3N7oZNY5K2RkRXo9t1bFs9TSaufYW0mZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeU4OZiZWY6Tg5mZ5Tg5mJlZjpODmZnlODmYmVmOk4OZmeVUnRwkLZW0XVK/pGtLLP+YpCfSJOz3SuooWjYk6eH06B29rlmzOK7NMlXNBCepDbgBOJ9s3twtknoj4omiag8BXRExKGk18FngA2nZ7yPiLZPot1nNOa7NXlXtnsMSoD8idkTEQeA2YFlxhYi4PyIG08sHySZbN2tljmuzpNrkcCrwbNHrXamsnCuA7xe9fo2kPkkPSnpflX0wqzXHtVlS1WElQCXKSk5GLWkF0AX8aVHx3IjYLWk+cJ+kxyLi6VHrdQPdAHPnzq2ym2YTUve4Tus6tq3lVbvnsAs4vej1acDu0ZUknQesAS6KiAPD5RGxO/3cATwAnD163YjoiYiuiOiaM2dOld00m5C6x3Va7ti2lldtctgCLJA0T9JMYDkwYnSGpLOBL5J9gV4oKp8l6Zj0fDbwDqD4hJ9ZsziuzZKqDitFxCFJVwN3A23A+ojYJuk6oC8ieoG/A14L3CkJ4JmIuAh4E/BFSYfJktOnR40GMWsKx7XZqxRR8pBqS+nq6oq+vr5md8OmMUlbI6Kr0e06tq2eJhPXvkLazMxynBzMzCzHycHMzHKcHMzMLMfJwczMcpwczMwsx8nBzMxynBzMzCzHycHMzHKcHMzMLMfJwczMcpwczMwsx8nBzMxynBzMzCzHycHMzHKcHMzMLKfq5CBpqaTtkvolXVti+TGSbk/LfyKps2jZx1P5dknvqbYPZvXg2DarMjlIagNuAC4AFgKXSlo4qtoVwP6IOAP4HPCZtO5Csrl5zwKWAuvS+5k1nWPbLFPtnsMSoD8idkTEQeA2YNmoOsuAm9Pzu4BzlU26uwy4LSIORMTPgf70fmatwLFtRvXJ4VTg2aLXu1JZyToRcQj4NXBSheuaNYtj2wyYUeV6KlEWFdapZF0kdQPd6eUBSY9PqIe1Mxt48Qhqt5ltN3Ob35B+Orbd7nRq+w3jVymt2uSwCzi96PVpwO4ydXZJmgEcD+yrcF0iogfoAZDUFxFdVfZ1UprVtre58W2np45ttztt2i6K6wmr9rDSFmCBpHmSZpKdhOsdVacXWJmeXwzcFxGRypenER/zgAXA5ir7YVZrjm0zqtxziIhDkq4G7gbagPURsU3SdUBfRPQCXwFukdRP9l/V8rTuNkl3AE8Ah4CPRMRQDbbFbNIc22ZJRLT8A+g+0tr2Nh8ZbXubp3+7U3Wbld7AzMzsFb59hpmZ5bRUcpjMbQsa0PbHJD0h6VFJ90rqaES7RfUulhSSajLioZJ2Jf3ntM3bJH2jFu1W0rakuZLul/RQ+rwvrFG76yW9UG7oqDKfT/16VNJba9Fueu+mxHaz4rqStovqObYn12Z94rpZx+BKHBtrA54G5gMzgUeAhaPqXAXclJ4vB25vYNt/BrSn56tr0XYl7aZ6xwE/AB4Euhq0vQuAh4BZ6fUfNfCz7gFWp+cLgZ01avtdwFuBx8ssvxD4Ptn1Cm8HfjKVY7tZce3Ybmxs1yuuW2nPYTK3Lah72xFxf0QMppcPko1hr3u7yaeAzwJ/qEGblbb7X4AbImI/QES80MC2A3hden48Ja4VqEZE/IBsdFE5y4CvR+ZB4ARJJ9eg6WbFdrPiuqK2E8f2JNUrrlspOUzmtgWNaLvYFWSZuO7tSjobOD0i/qkG7VXcLnAmcKakH0l6UNLSBrb9SWCFpF3A94C/qlHb46nX7S+aFdvNiuuK2nZsNyy2q4rraq+QrofJ3LagEW1nFaUVQBfwp/VuV9JRZHf9vLwGbVXcbjKDbPf7HLL/Jn8oaVFE/KoBbV8KfC0i/l7Sn5BdU7AoIg5Psu1a9K1e71uPtpsV1+O27dhuaGxXFVuttOcwkdsWoJG3LWhE20g6D1gDXBQRBxrQ7nHAIuABSTvJjhf21uDEXaWf9bcj4uXI7jC6newLNVmVtH0FcAdARPwYeA3ZvWnqraI4qNP71iO2mxXXlbTt2G5cbFcX17U4EVOjkzkzgB3APF49mXPWqDofYeRJuzsa2PbZZCebFjRym0fVf4DanLSrZHuXAjen57PJdktPalDb3wcuT8/flAJZNfrMOyl/4u69jDxxt3kqx3az4tqx3fjYrkdc1ywYahRQFwI/S8G6JpVdR/YfDWRZ9k6y++RvBuY3sO1NwC+Bh9OjtxHtjqpbky9Qhdsr4B/IbgXxGLC8gZ/1QuBH6cv1MPDuGrV7K/A88DLZf1NXAFcCVxZt8w2pX4/V6rNuZmw3K64d242L7XrFta+QNjOznFY652BmZi3CycHMzHKcHMzMLMfJwczMcpwczMwsx8nBzMxynBzMzCzHycHMzHL+P1Sx3m6Za4I6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,2)\n",
    "\n",
    "color = test_labels.cpu()*85/255\n",
    "for i in range (len(test_labels)):\n",
    "    axs[0,0].scatter(m[i,0],m[i,1],color=(0,color[i],0))\n",
    "    axs[0,1].scatter(Y[i,0],Y[i,1],color=(0,color[i],0))\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "266.823px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
