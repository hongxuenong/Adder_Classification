{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[1101], edge_index=[2, 4238], x=[1101, 3], y=[32])\n",
      "Batch(batch=[975], edge_index=[2, 3646], x=[975, 3], y=[32])\n",
      "Batch(batch=[1137], edge_index=[2, 4196], x=[1137, 3], y=[32])\n",
      "Batch(batch=[1030], edge_index=[2, 3924], x=[1030, 3], y=[32])\n",
      "Batch(batch=[1015], edge_index=[2, 4046], x=[1015, 3], y=[32])\n",
      "Batch(batch=[1079], edge_index=[2, 4286], x=[1079, 3], y=[32])\n",
      "Batch(batch=[1088], edge_index=[2, 3850], x=[1088, 3], y=[32])\n",
      "Batch(batch=[1069], edge_index=[2, 4050], x=[1069, 3], y=[32])\n",
      "Batch(batch=[1034], edge_index=[2, 4064], x=[1034, 3], y=[32])\n",
      "Batch(batch=[998], edge_index=[2, 3834], x=[998, 3], y=[32])\n",
      "Batch(batch=[1172], edge_index=[2, 4728], x=[1172, 3], y=[32])\n",
      "Batch(batch=[922], edge_index=[2, 3480], x=[922, 3], y=[32])\n",
      "Batch(batch=[1061], edge_index=[2, 4064], x=[1061, 3], y=[32])\n",
      "Batch(batch=[1083], edge_index=[2, 4114], x=[1083, 3], y=[32])\n",
      "Batch(batch=[871], edge_index=[2, 3314], x=[871, 3], y=[32])\n",
      "Batch(batch=[1058], edge_index=[2, 4114], x=[1058, 3], y=[32])\n",
      "Batch(batch=[998], edge_index=[2, 3820], x=[998, 3], y=[32])\n",
      "Batch(batch=[963], edge_index=[2, 3724], x=[963, 3], y=[32])\n",
      "Batch(batch=[926], edge_index=[2, 3072], x=[926, 3], y=[24])\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "for batch in loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,in_dim, hidden_dim, n_classes):\n",
    "        super(PYGNet, self).__init__()\n",
    "#         self.lin = Sequential(Linear(10, 10))\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.classify = nn.Linear(hidden_dim, n_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = torch.mean(x, 0, True)\n",
    "        return self.classify(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epoch = 80 #original = 1500 for 1 training sample 500 for 20 samples\n",
    "initial_lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "#model = Classifier(1, 256, trainset.num_classes)\n",
    "import time\n",
    "\n",
    "model = PYGNet(1, 256, 4)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = initial_lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "#start timer:\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in loader:\n",
    "        x = batch.x\n",
    "        edges = batch.edge_index\n",
    "        labels = batch.y\n",
    "        prediction = model(x,edges)\n",
    "\n",
    "        loss = loss_func(prediction, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "    epoch_loss /= (iter + 1)\n",
    "    print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
    "    epoch_losses.append(epoch_loss)\n",
    "\n",
    "training_time = time.time() - t0\n",
    "\n",
    "print('Finished training. Training time = {:.4f} Seconds'.format(training_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
